import streamlit as st
import hashlib
import requests
import os
import pytz
import time
import unicodedata
import importlib.metadata
import re
import tempfile
import uuid
from pydantic import BaseModel, validator
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.http import models
from typing import List, Optional, Union, Dict, Any, Literal, Set
from datetime import datetime, timedelta
from collections import defaultdict
from PyPDF2 import PdfReader
from docx import Document
from unstructured.partition.pdf import partition_pdf  # Optionnel, pour une extraction plus fine
from unstructured.partition.docx import partition_docx

try:
    import pdfplumber
    print("‚úÖ pdfplumber est install√© et fonctionnel.")
except ImportError:
    print("‚ùå pdfplumber n'est pas install√©. Ex√©cutez : pip install pdfplumber")
    raise

#################################################################
# 1. CLASSES, FONCTIONS UTILITAIRES, INITIALISATION DES VARIABLES
#################################################################

# --- Persistance de l'historique via session_state ---
def save_historique():
    # Limite le nombre d'entr√©es pour √©viter la surcharge (ex: 50 derni√®res)
    if len(st.session_state.full_historique) > 50:
        # Supprime les entr√©es les plus anciennes
        sorted_entries = sorted(
            st.session_state.full_historique.items(),
            key=lambda x: x[1]["metadata"].get("timestamp", "")
        )
        st.session_state.full_historique = dict(sorted_entries[-50:])
    st.session_state.historique_cache = st.session_state.full_historique.copy()

def load_historique():
    if "historique_cache" in st.session_state:
        st.session_state.full_historique = st.session_state.historique_cache.copy()

# Pour permettre de renommer une collection
if 'show_rename_modal' not in st.session_state:
    st.session_state.show_rename_modal = False
if 'current_doc_to_rename' not in st.session_state:
    st.session_state.current_doc_to_rename = None

# Initialisation des √©tats de certaines variables si non existants
if 'use_priority_docs' not in st.session_state:
    st.session_state.use_priority_docs = False
if 'priority_docs' not in st.session_state:
    st.session_state.priority_docs = []

# Estimation du nombre de tokens d'un texte en fran√ßais
def estimate_tokens(text):
    """Estime le nombre de tokens pour Mistral Large (1 token ‚âà 4 caract√®res en fran√ßais)."""
    return len(text) // 4

# Fonction utilitaire pour tronquer le texte
def truncate_text(text: str, max_tokens: int = 500) -> str:
    """Tronque un texte √† un nombre maximal de tokens (1 token ‚âà 4 caract√®res)."""
    max_chars = max_tokens * 4
    return (text[:max_chars] + "...") if len(text) > max_chars else text

# Fonction de conversion des dates
def safe_parse_date(date_str: Optional[str]) -> datetime:
    """Convertit une date h√©t√©rog√®ne en datetime, ou datetime.min si invalide."""
    if not date_str:
        return datetime.min
    for fmt in ("%Y-%m-%d", "%d/%m/%Y", "%Y/%m/%d"):
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    return datetime.min

# Cl√© num√©rique
def sort_key(article_num: str):
    """
    Transforme un identifiant d'article (ex: 'D146-12-1') en tuple num√©rique
    pour un tri correct.
    """
    if not article_num:
        return ("",)
    prefix = article_num[0]
    parts = re.findall(r'\d+', article_num)
    nums = [int(p) for p in parts]
    return (prefix, *nums)

# Charger l'historique au d√©marrage
load_historique()

# --- Configuration de la page (doit √™tre unique et en premier) ---
st.set_page_config(
    page_title="Parlement RAG",
    page_icon="üó≥Ô∏è",
    layout="wide"   # ‚Üê √©largit toute la page
)

# Classe  CSS pour tous les messages de statut
st.markdown("""
<style>
    /* ===== STYLES GLOBAUX ===== */
    /* Messages de statut (utilis√© par status_placeholder et prep_placeholder) */
    .status-message, .prep-message {
        display: flex;
        justify-content: center;
        align-items: center;
        margin: 0.5rem auto !important;
        padding: 0.7rem 1rem;
        text-align: center;
        font-size: 14px;
        color: #555;
        background-color: #f0f2f6;
        border-radius: 6px;
        max-width: 600px;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
    /* Style sp√©cifique pour les messages dans les onglets */
    .prep-message {
        min-height: 40px;
        font-size: 15px;
    }
    /* Conteneur principal */
    .stApp {
        display: flex;
        flex-direction: column;
    }
    .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
    }
    /* Expanders et contenu */
    div[data-testid="stExpander"] {
        margin: 0 auto 0.5rem auto !important;
        max-width: 1000px;
        width: 100%;
    }
    div.streamlit-expanderHeader {
        padding: 0.3rem 0.6rem !important;
        font-size: 13px !important;
        background-color: #f0f2f6 !important;
        border-radius: 4px !important;
    }
    div.streamlit-expanderContent {
        padding: 0.5rem 0.8rem !important;
        text-align: justify;
    }
    /* Titres et s√©parateurs */
    h3 {
        text-align: center;
        margin: 0.4rem auto !important;
        color: #0066cc;
    }
    hr {
        margin: 0.3rem auto;
        width: 80%;
        border: none;
        border-top: 1px solid #ddd;
    }
    /* Suppression des marges inutiles */
    .stMarkdown > div {
        margin: 0 !important;
    }
    p, ul, ol {
        margin: 0.2rem 0 !important;
        padding: 0 !important;
    }
    /* Style pour les expanders de l'historique */
    div[data-testid="stExpander"] > details > summary {
        padding: 0.5rem 1rem !important;
        background-color: #f0f2f6 !important;
        border-radius: 6px !important;
        margin-bottom: 0.5rem !important;
    }
    /* Espacement entre les entr√©es */
    .history-entry {
        margin-bottom: 1rem !important;
    }
</style>
""", unsafe_allow_html=True)

# --- 1. Chargement des variables d'environnement ---
load_dotenv()
QDRANT_URL = os.getenv("QDRANT_URL", "").strip()
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY", "").strip()
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "").strip()
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "").strip()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "").strip()
GOOGLE_CX = os.getenv("GOOGLE_CX", "").strip()

QDRANT_COLLECTION = "QuestionParlementaire"

if not QDRANT_URL.startswith("https://"):
    raise RuntimeError("‚ùå QDRANT_URL doit commencer par https://")
if not QDRANT_API_KEY:
    raise RuntimeError("‚ùå QDRANT_API_KEY manquant. V√©rifiez votre fichier .env")
if not MISTRAL_API_KEY:
    raise RuntimeError("‚ùå MISTRAL_API_KEY manquant. V√©rifiez votre fichier .env")

print("QDRANT_URL:", QDRANT_URL)
print("QDRANT_API_KEY (d√©but):", QDRANT_API_KEY[:10], "...")

# --- 3. Chargement du mod√®le ---
LOCAL_MODEL_PATH = "./models/camembert_finetuned_progressive"
HUB_MODEL_PATH = "Whisler/camembert_finetuned_progressive"

@st.cache_resource
def load_embedding_model():
    try:
        if os.path.exists(LOCAL_MODEL_PATH):
            model = SentenceTransformer(LOCAL_MODEL_PATH)
            print("‚úÖ Mod√®le charg√© en local.")
        else:
            model = SentenceTransformer(HUB_MODEL_PATH)
            print("‚úÖ Mod√®le t√©l√©charg√© depuis HuggingFace Hub.")
        test_embedding = model.encode("Test de chargement du mod√®le.")
        VECTOR_SIZE = len(test_embedding)
        print("Dimension des embeddings:", VECTOR_SIZE)
        return model
    except Exception as e:
        st.error(f"‚ùå Erreur de chargement du mod√®le: {str(e)}")
        raise

embedding_model = load_embedding_model()

# --- 4. Connexion √† Qdrant ---
try:
    qdrant_client = QdrantClient(
        url=QDRANT_URL,
        api_key=QDRANT_API_KEY,
        timeout=10.0,
        check_compatibility=False
    )
    collections = qdrant_client.get_collections()
    print(f"‚úÖ Connexion r√©ussie. Collections disponibles: {[c.name for c in collections.collections]}")
except Exception as e:
    print(f"‚ùå Erreur de connexion √† Qdrant: {e}")
    raise


# --- 5. Mod√®les Pydantic ---

# Modele Pydantic pour les articles juridiques
class BaseLegislativeRef(BaseModel):
    uid: str
    collection: str

class RetrievedLegalDocument(BaseModel):
    # Identifiants
    chunk_id: str
    num: str
    titre: str
    
    # Contenu
    contenu: str
    article_complet: str
    
    # Contexte
    contexte_hierarchique: str
    collection: str
    
    # Hi√©rarchie optionnelle
    partie: Optional[str] = None
    livre: Optional[str] = None
    titre_structure: Optional[str] = None
    chapitre: Optional[str] = None
    section: Optional[str] = None
    sous_section: Optional[str] = None
    paragraphe: Optional[str] = None
    sous_paragraphe: Optional[str] = None
    
    # R√©f√©rences l√©gislatives
    base_legislative: Optional[List[BaseLegislativeRef]] = None
    
    # Score du retrieval
    score: Optional[float] = None

# Modele Pydantic pour les documents generiques
class GenericDocument(BaseModel):
    # Identifiants
    uid: Optional[str] = None
    
    # Contenu
    text: str
    title: Optional[str] = None
    part: Optional[str] = None   # ex. "Annexe 7", "partie 1"
    
    # M√©tadonn√©es
    source: Optional[str] = None
    date_document: Optional[str] = None
    type_document: Optional[str] = None
    
    # Score du retrieval
    score: Optional[float] = None

# Modele Pydantic pour les reponses RAG
class ResponseDocument(BaseModel):
    # Identifiants
    uid: str
    # Contenu
    question: str
    reponse: str
    # M√©tadonn√©es
    legislature: Optional[str] = None
    chambre: Optional[str] = None   # Assembl√©e ou S√©nat (√† ajouter si tu l‚Äôas dans tes donn√©es)
    rubrique: Optional[str] = None
    analyse: Optional[str] = None
    ministeres_attribues: Optional[List[str]] = None
    # Dates
    date_question: Optional[str] = None
    date_reponse: Optional[str] = None
    # R√©f√©rences juridiques √©ventuelles
    textes_juridiques: Optional[List[str]] = None
    # Score du retrieval
    score: Optional[float] = None


#################################################################
# -------------- 2. PRINCIPALES FONCTIONS -----------------------
#################################################################

# --- 2a. Fonctions d'upload, d'indexation et d'embedding

# Fonction pour extraire le texte d'un document pdf
def extract_text(pdf_path: str, max_pages: Optional[int] = None) -> str:
    """Extrait le texte d'un PDF, avec gestion des erreurs et des pages vides (VOTRE FONCTION)."""
    text = []
    try:
        with pdfplumber.open(pdf_path) as pdf:
            pages = pdf.pages[:max_pages] if max_pages else pdf.pages
            for page in pages:
                page_text = page.extract_text() or ""
                if page_text.strip():  # Ignore les pages vides
                    text.append(page_text)
    except Exception as e:
        st.error(f"‚ùå Erreur lors de l'extraction du PDF: {e}")
        return ""
    return "\n".join(text)

# Fonction pour extraire le texte d'un document Word
def extract_text_from_docx(file_path: str, use_unstructured: bool = False) -> str:
    """Extrait le texte d'un fichier Word."""
    if use_unstructured:
        elements = partition_docx(file_path)
        text = "\n\n".join([str(el) for el in elements])
    else:
        doc = Document(file_path)
        text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])
    return text.strip()

# Fonction pour nettoyer les textes extraits
def clean_text(text: str) -> str:
    """Nettoie le texte en supprimant les lignes trop courtes, les num√©ros de page et les artefacts (VOTRE FONCTION AM√âLIOR√âE)."""
    lines = text.split('\n')
    cleaned_lines = []
    for line in lines:
        line = line.strip()
        # Ignorer les lignes trop courtes ou purement num√©riques
        if len(line) > 10 and not re.match(r'^\d+$', line.strip()):
            cleaned_lines.append(line)
    text = '\n'.join(cleaned_lines)
    # Supprimer les espaces multiples et sauts de ligne redondants
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'(\w)-\s+(\w)', r'\1\2', text)  # Recolle les mots coup√©s
    text = re.sub(r'\b\d{1,3}\b(?=\s|$|\.|\,)', '', text)  # Supprime les nombres isol√©s
    text = re.sub(r'PLFSS\s*20\d{2}\s*-\s*Annexe\s*\d+', "", text, flags=re.IGNORECASE)
    text = re.sub(r"Source\s*:.*?(?=\n|$)", "", text, flags=re.IGNORECASE)
    text = re.sub(r"[‚Ä¢‚óã‚óò]\s*|\bPage\s+\d+\b", "", text)
    text = re.sub(r"\bhttps?://\S+|\[.*?\]", "", text)
    return text.strip()

# Fonction de suppression du sommaire
def remove_summary(text: str) -> str:
    """Supprime le sommaire et les tables des mati√®res (VOTRE FONCTION)."""
    cleaned = re.sub(
        r"(?i)(SOMMAIRE|TABLE DES MATI√àRES).*?(?=PARTIE\s+\d+|ANNEXE\s+\d+|Article\s+\d+|$)",
        "",
        text,
        flags=re.DOTALL
    )
    return cleaned.strip() if cleaned.strip() else text

# Fonction de pr√©-traitement des titres
def preprocess_for_titles(text: str) -> str:
    """Ins√®re des sauts de ligne avant chaque titre (VOTRE FONCTION OPTIMIS√âE)."""
    sentences = re.split(r'(?<=[.!?])\s+', text)
    processed_text = []
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        if detect_titles(sentence):
            processed_text.append(f"\n{sentence}\n")
        else:
            processed_text.append(sentence)
    text = " ".join(processed_text)
    title_patterns = [
        r"(Article\s*\d*\s*[-‚Äì]?)", r"(ANNEXE\s+\d+)", r"(PARTIE\s+\d+)",
        r"(Fiches?\s+d‚Äô?√©valuation\s+pr√©alable)", r"(\d+\.\s+)", r"([IVXLCDM]+\.\s+)"
    ]
    for pattern in title_patterns:
        text = re.sub(pattern, r"\n\1\n", text, flags=re.IGNORECASE)
    text = re.sub(r'\n\s*\n', '\n', text)
    return text.strip()

# Fonction de d√©tection des titres
def detect_titles(line: str) -> bool:
    """D√©tecte les titres de mani√®re robuste."""
    line = line.strip()
    if not line:
        return False
    regex_patterns = [
        r"^Article\s+\d+\s*[‚Äì‚Äî-]", r"^ANNEXE\s+\d+", r"^PARTIE\s+\d+",
        r"^(TITRE|Chapitre|Section)\s+\d+", r"^[IVXLCDM]+\.\s+", r"^\d+(\.\d+)*\s+"
    ]
    if any(re.match(p, line, flags=re.IGNORECASE) for p in regex_patterns):
        return True
    title_keywords = [
        "Article ", "ANNEXE ", "PARTIE ", "Fiches d‚Äô√©valuation pr√©alable",
        "Synth√®se", "Conclusion", "TITRE ", "Chapitre ", "Section ",
        "I. ", "II. ", "III. ", "1. ", "2. "
    ]
    return any(keyword.lower() in line.lower() for keyword in title_keywords)

# Fonction de segmentation du texte
def segment_text(text: str, max_words: int = 300, min_words: int = 50) -> List[Dict[str, str]]:
    """D√©coupe le texte en segments avec titres (VOTRE FONCTION ADAPT√âE POUR QDRANT)."""
    blocks = re.split(r'\n\n|\.\s+', text)
    segments = []
    current_title = "AUTRE"
    current_content = []
    for block in blocks:
        block = block.strip()
        if not block:
            continue
        if detect_titles(block):
            if current_content:
                seg_text = ' '.join(current_content)
                if len(seg_text.split()) >= min_words:
                    segments.append({"title": current_title, "text": seg_text})
                current_content = []
            current_title = block
        else:
            current_content.append(block)
    if current_content:
        seg_text = ' '.join(current_content)
        if len(seg_text.split()) >= min_words:
            segments.append({"title": current_title, "text": seg_text})
    return segments

# Fonction pour pr√©parer les chunks
def prepare_chunks_fixed(text: str, file_name: str, chunk_size=350, overlap=50) -> List[Dict]:
    """
    D√©coupe le texte en chunks fixes (~350 mots ‚âà 512 tokens) avec overlap,
    en conservant le dernier titre d√©tect√© comme m√©tadonn√©e.
    """
    import uuid
    words = text.split()
    chunks = []
    start = 0
    current_title = "AUTRE"

    while start < len(words):
        end = start + chunk_size
        chunk_words = words[start:end]

        # Met √† jour le titre courant si un mot ressemble √† un titre
        for w in chunk_words:
            if detect_titles(w):
                current_title = w

        if len(chunk_words) >= 50:  # filtre chunks trop courts
            chunk_text = " ".join(chunk_words)
            chunks.append({
                "id": str(uuid.uuid4()),
                "text": chunk_text,
                "metadata": {
                    "source": file_name,
                    "section": current_title,  # dernier titre d√©tect√©
                    "position": start,
                    "word_count": len(chunk_words),
                    "upload_date": datetime.now().isoformat()
                }
            })
        start += chunk_size - overlap  # avance avec recouvrement

    return chunks

# Fonction pour l'upload et l'indexation
def process_and_index_document(file_path: str, file_type: str, collection_name: str, progress_callback=None, **kwargs):
    """Traite et indexe un document dans SA PROPRE COLLECTION avec suivi de progression et gestion des timeouts."""
    try:
        # 1. Extraction du texte
        if file_type == "pdf":
            raw_text = extract_text(file_path)
        else:
            raw_text = extract_text_from_docx(file_path)

        if not raw_text:
            if progress_callback:
                progress_callback(0, 1, "√âchec : extraction du texte")
            return False

        if progress_callback:
            progress_callback(5, 100, "Extraction du texte termin√©e")

        # 2. Nettoyage et segmentation
        cleaned_text = clean_text(raw_text)
        segments = segment_text(cleaned_text) or [{"title": "Document", "text": cleaned_text}]

        if progress_callback:
            progress_callback(10, 100, "Nettoyage et segmentation termin√©s")

        # 3. Pr√©paration des chunks fixes avec overlap
        preprocessed_text = preprocess_for_titles(cleaned_text)
        chunks = prepare_chunks_fixed(
            preprocessed_text,
            file_name=collection_name,
            chunk_size=350,   # ‚âà 512 tokens
            overlap=50        # recouvrement pour ne pas perdre de contexte
        )

        if progress_callback:
            progress_callback(30, 100, f"Pr√©paration des chunks termin√©e ({len(chunks)} chunks)")

        # 4. G√©n√©ration des embeddings (par petits lots)
        texts = [chunk["text"] for chunk in chunks]
        total_chunks = len(chunks)
        embeddings = []

        for i in range(0, len(texts), 5):  # R√©duit √† 5 chunks par lot pour √©viter la surcharge
            batch_texts = texts[i:i+5]
            try:
                batch_embeddings = embedding_model.encode(batch_texts).tolist()
                embeddings.extend(batch_embeddings)
            except Exception as e:
                if progress_callback:
                    progress_callback(0, 100, f"Erreur g√©n√©ration embeddings: {str(e)}")
                return False

            if progress_callback:
                current_chunk = min(i + 5, total_chunks)
                progress_callback(30 + int(30 * current_chunk / total_chunks),
                                100,
                                f"G√©n√©ration des embeddings : {current_chunk}/{total_chunks}")

        # 5. Indexation dans Qdrant (par petits lots avec r√©essais)
        points = []
        for chunk, embedding in zip(chunks, embeddings):
            points.append(
                models.PointStruct(
                    id=chunk["id"],
                    vector=embedding,
                    payload={
                        "text": chunk["text"],   # ‚Üê ajoute le texte du chunk
                        **chunk["metadata"]      # ‚Üê conserve les m√©tadonn√©es
                    }
                )
            )
            
        # R√©duit la taille des batches et r√©essais
        batch_size = 10  # R√©duit de 50 √† 10
        max_retries = 2   # Nombre maximal de r√©essais
        retry_delay = 2   # D√©lai entre les r√©essais en secondes

        for i in range(0, len(points), batch_size):
            batch = points[i:i + batch_size]
            retry_count = 0
            success = False

            for i in range(0, len(points), batch_size):
                batch = points[i:i+batch_size]
                try:
                    qdrant_client.upsert(
                        collection_name=collection_name,
                        points=batch,
                        wait=True,
                    )
                except Exception as e:
                    st.error(f"Erreur Qdrant batch {i//batch_size+1}: {e}")
                    st.write("Exemple point:", batch[0].vector[:10], "dim=", len(batch[0].vector))
                    return False

            while retry_count < max_retries and not success:
                try:
                    kwargs["qdrant_client"].upsert(
                        collection_name=collection_name,
                        points=batch,
                        wait=True,
                    )
                    success = True
                except Exception as e:
                    retry_count += 1
                    if progress_callback:
                        progress_callback(0, 100, f"√âchec batch {i//batch_size + 1}, tentative {retry_count}/{max_retries}")
                    if retry_count < max_retries:
                        time.sleep(retry_delay)  # Attend avant de r√©essayer

            if not success:
                if progress_callback:
                    progress_callback(0, 100, f"√âchec d√©finitif batch {i//batch_size + 1}")
                return False

            if progress_callback:
                current_point = min(i + batch_size, len(points))
                progress_callback(60 + int(40 * current_point / len(points)),
                                100,
                                f"Indexation : {current_point}/{len(points)} chunks")

        if progress_callback:
            progress_callback(100, 100, "Indexation termin√©e avec succ√®s")
        return True

    except Exception as e:
        if progress_callback:
            progress_callback(0, 100, f"Erreur : {str(e)}")
        st.error(f"Erreur dans process_and_index_document: {e}")
        return False

# --- 2b. Fonctions de recherche ---

# Fonction qui supprime les accents
def normalize_query(query: str) -> str:
    # Supprime les accents et normalise en ASCII
    return ''.join(
        c for c in unicodedata.normalize('NFD', query)
        if unicodedata.category(c) != 'Mn'
    )

# Fonction qui extrait le sujet principal de la question
def extract_subject(question: str) -> str:
    """
    Extrait le sujet principal d'une question parlementaire sous forme de 3 √† 5 mots-cl√©s.
    - Supprime toute mention de d√©put√©s, du Gouvernement ou de formulations inutiles.
    - Nettoie la ponctuation et tronque √† quelques mots.
    """
    url = "https://api.mistral.ai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "mistral-small-latest",  # possibilit√© de remplacer "small" par "medium"
        "messages": [
            {
                "role": "system",
                "content": (
                    "Tu es un assistant qui identifie uniquement le sujet principal "
                    "d'une question parlementaire. "
                    "Ne mentionne jamais le d√©put√© ou le gouvernement. "
                    "Donne une r√©ponse sous forme de 3 √† 5 mots-cl√©s concis, "
                    "centr√©s sur le th√®me (pas de phrase compl√®te)."
                )
            },
            {
                "role": "user",
                "content": question
            }
        ],
        "temperature": 0.2,
        "max_tokens": 20
    }

    response = requests.post(url, headers=headers, json=payload)
    response.raise_for_status()
    data = response.json()

    try:
        subject = data["choices"][0]["message"]["content"].strip()
    except (KeyError, IndexError):
        subject = "sujet non identifi√©"

    # Nettoyage suppl√©mentaire c√¥t√© Python
    subject = re.sub(r"\b(d√©put√©e?|d√©put√©|gouvernement|ministre|assembl√©e nationale|s√©nat)\b", "", subject, flags=re.IGNORECASE)
    subject = subject.replace("**Sujet principal**", "").strip()
    subject = re.sub(r"[^\w\s]", " ", subject)  # supprime ponctuation
    subject = re.sub(r"\s+", " ", subject)

    # Tronquer √† 5 mots max
    tokens = subject.split()
    subject = " ".join(tokens[:5])

    print("=== Sujet extrait (compact) ===", subject)

    return subject

# Fonction de recherche Tavily (et filtre pour les scores de pertinence <0.5)
def search_tavily_government(subject: str, min_score: float = 0.5):
    """
    Recherche les annonces gouvernementales r√©centes sur un sujet donn√© via Tavily.
    - Filtre par domaines autoris√©s
    - Filtre par date (moins d'un an si disponible)
    - Filtre par score de pertinence (>= min_score)
    """

    url = "https://api.tavily.com/search"
    headers = {"Authorization": f"Bearer {TAVILY_API_KEY}"}

    allowed_domains = [
        "gouvernement.fr", "education.gouv.fr", "vie-publique.fr", "elysee.fr",
        "solidarites.gouv.fr", "sante.gouv.fr", "travail-sante-solidarites.gouv.fr",
        "securite-sociale.fr", "ameli.fr", "lassuranceretraite.fr", "caf.fr",
        "msa.fr", "urssaf.fr", "legifrance.gouv.fr", "drees.solidarites-sante.gouv.fr",
        "ars.sante.fr", "cnsa.fr", "en3s.fr", "francetravail.fr"
    ]

    payload = {
        "query": f"derni√®res annonces gouvernement France {subject}",
        "max_results": 100,
        "include_answer": True,
        "include_domains": allowed_domains
    }

    response = requests.post(url, json=payload, headers=headers)
    response.raise_for_status()

    data = response.json()
    raw_results = data.get("results", [])

    # Filtre par domaine
    by_domain = [r for r in raw_results if any(d in r.get("url", "") for d in allowed_domains)]

    # Filtre par date (moins d'un an si dispo)
    cutoff = datetime.now() - timedelta(days=365)
    recent = []
    for r in by_domain:
        ds = r.get("published_date") or r.get("date")
        if ds:
            try:
                pub = datetime.fromisoformat(ds.replace("Z", ""))
                # ‚úÖ Condition suppl√©mentaire : ann√©e 2025
                if pub.year == 2025 or pub >= cutoff:
                    recent.append(r)
                    continue
                else:
                    continue
            except Exception:
                # date non exploitable ‚Üí on garde
                recent.append(r)
        else:
            recent.append(r)

    # Filtre par score
    filtered = [r for r in recent if r.get("score", 0) >= min_score]
    filtered.sort(key=lambda x: x.get("score", 0), reverse=True)

    # ‚úÖ Limiter √† 10 apr√®s filtrage
    data["results"] = filtered[:10]

    return data

# Fonction de recherche Google
def search_google_government(subject: str,
                             min_score: float = 0.5,
                             max_results: int = 10):
    """
    Recherche des informations via Google Custom Search API sur un sujet donn√©.
    - M√™me structure et format que search_tavily_government
    - Entr√©e: subject (str), min_score, max_results
    - Sortie: dict {"results": [{"title","url","content","score","published_date"}]}
    """

    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        "q": f"derni√®res annonces gouvernement France {subject}",
        "key": GOOGLE_API_KEY,
        "cx": GOOGLE_CX,
        "num": max_results
    }

    response = requests.get(url, params=params, timeout=20)
    response.raise_for_status()
    data = response.json()

    raw_results = data.get("items", [])
    allowed_domains = [
        "gouvernement.fr", "info.gouv.fr", "elysee.fr", "vie-publique.fr",
        "education.gouv.fr", "solidarites.gouv.fr", "sante.gouv.fr",
        "travail-sante-solidarites.gouv.fr", "securite-sociale.fr", "ameli.fr",
        "lassuranceretraite.fr", "caf.fr", "msa.fr", "urssaf.fr",
        "legifrance.gouv.fr", "drees.solidarites-sante.gouv.fr", "ars.sante.fr",
        "cnsa.fr", "en3s.fr", "francetravail.fr"
    ]

    # Filtre par domaine
    by_domain = [r for r in raw_results if any(d in r.get("link", "") for d in allowed_domains)]

    # Filtre par date (moins d'un an si dispo)
    cutoff = datetime.now() - timedelta(days=365)
    recent = []
    for r in by_domain:
        date_str = r.get("pagemap", {}).get("metatags", [{}])[0].get("article:published_time")
        if date_str:
            try:
                pub = datetime.fromisoformat(date_str.replace("Z", ""))
                if pub >= cutoff:
                    recent.append(r)
            except Exception:
                recent.append(r)
        else:
            recent.append(r)

    # Filtre par score (Google ne fournit pas de score ‚Üí fallback = 1.0 si snippet pr√©sent)
    filtered = [r for r in recent if r.get("snippet")]
    filtered = filtered[:max_results]

    # Format homog√®ne comme Tavily
    results = []
    for r in filtered:
        results.append({
            "title": r.get("title", ""),
            "url": r.get("link", ""),
            "content": r.get("snippet", ""),   # Tavily utilisait "content"
            "score": 1.0,                      # Valeur par d√©faut
            "published_date": date_str if r.get("pagemap", {}).get("metatags") else None
        })

    return {"results": results}

# --- Fonction de log pour le debug ---
def log_debug(title: str, data: Any, max_length: int = 500):
    """Affiche un log de debug dans un fichier."""
    import os
    from datetime import datetime

    # Chemin absolu vers le dossier de logs (dans le r√©pertoire courant)
    log_dir = os.path.join(os.getcwd(), "logs")

    # Cr√©er le dossier s'il n'existe pas
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
        print(f"üìÅ Dossier cr√©√© : {log_dir}")

    # Chemin absolu vers le fichier de log
    log_file = os.path.join(log_dir, "debug_logs.txt")

    try:
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(f"\n--- {title} ---\n")
            f.write(f"Timestamp: {datetime.now().isoformat()}\n")
            if isinstance(data, dict):
                for k, v in data.items():
                    f.write(f"{k}: {str(v)[:max_length]}\n")
            elif isinstance(data, list):
                f.write(f"List of {len(data)} items:\n")
                for i, item in enumerate(data[:3]):
                    f.write(f"  Item {i}: {str(item)[:max_length]}\n")
            else:
                f.write(f"{str(data)[:max_length]}\n")
            f.write("---\n")

        # Confirmation dans le terminal
        print(f"‚úÖ Log enregistr√© dans {log_file}: {title}")

    except Exception as e:
        print(f"‚ùå Erreur lors de l'√©criture du log : {str(e)}")

# Fonctions utilitaires car le champ base_legislative peut contenir soit des objets BaseLegislativeRef, soit des dicts (selon la provenance des donn√©es)
def get_ref_uid(ref) -> str | None:
    return ref.uid if hasattr(ref, "uid") else ref.get("uid")

def get_ref_collection(ref, default_collection: str) -> str:
    return ref.collection if hasattr(ref, "collection") else ref.get("collection", default_collection)

# Pr√©parer pour pr√©parer le contenu en vue d'un export .txt
def build_export_content(response_data: dict, mode: str, include_legal_articles: bool = False) -> str:
    lines = []

    # Question
    question = response_data.get("question")
    if question:
        lines.append("‚ùì Question\n")
        lines.append(str(question))
        lines.append("\n\n")

    # En-t√™te (R√©ponse ou Analyse)
    if mode == "analyse":
        lines.append("üîé Analyse juridique\n")
    else:
        lines.append("üìú R√©ponse\n")
    lines.append(str(response_data.get("response", "Pas de texte g√©n√©r√©")))
    lines.append("\n\n")

    # R√©sum√© (si pr√©sent)
    summary = response_data.get("summary")
    if summary:
        lines.append("üìù R√©sum√©\n")
        lines.append(str(summary))
        lines.append("\n\n")

    # R√©sultats de recherche (si pr√©sents)
    search_results = response_data.get("search_results", [])
    if search_results:
        lines.append("üåê R√©sultats de recherche\n")
        for idx, item in enumerate(search_results, start=1):
            titre = item.get("title", "Sans titre")
            url = item.get("url", "")
            extrait = item.get("content") or item.get("snippet") or ""
            score = item.get("score", "N/A")
            date = item.get("published_date", "N/A")
            lines.append(f"{idx}. {titre}\n")
            if url:
                lines.append(f"   Lien: {url}\n")
            if extrait:
                lines.append(f"   Extrait: {extrait}\n")
            lines.append(f"   Score: {score} | Date: {date}\n\n")

    # Anciennes QE (si pr√©sentes)
    lines.append("üèõÔ∏è Anciennes QE\n")
    for doc in response_data.get("similar_documents", []):
        score = f"{getattr(doc, 'score', 0):.2f}" if getattr(doc, "score", None) is not None else "N/A"
        chambre = getattr(doc, "chambre", "Inconnue")
        lines.append(f"- QE {doc.uid} ({chambre}) - Score : {score}\n")
        lines.append(f"  Question: {doc.question}\n")
        lines.append(f"  R√©ponse: {doc.reponse}\n\n")

    # Articles juridiques (pour les deux modes)
    if mode == "analyse" or include_legal_articles:
        lines.append("‚öñÔ∏è Articles juridiques\n")

        # Mode "Analyse juridique" : utilise "sources" (avec relations parents/enfants)
        if mode == "analyse":
            sources = response_data.get("sources", [])
            if not sources:
                lines.append("Aucun article juridique enregistr√©.\n")
            else:
                for source in sources:
                    art = source["article"]
                    lines.append(f"--- Article {art.num} ({art.collection}) ---\n")
                    lines.append(f"Titre: {art.titre}\n")
                    lines.append(f"Texte: {art.article_complet}\n")

                    # Relations parents (articles cit√©s)
                    if source.get("parents"):
                        lines.append("Articles cit√©s:\n")
                        for parent in source["parents"]:
                            lines.append(f"- {parent.num}: {parent.titre}\n")

                    # Relations enfants (r√©f√©renc√© par)
                    if source.get("enfants"):
                        lines.append("R√©f√©renc√© par:\n")
                        for enfant in source["enfants"]:
                            lines.append(f"- {enfant.num}: {enfant.titre}\n")
                    lines.append("\n")

        # Mode "R√©ponse parlementaire" : utilise "legal_sources" (sans relations)
        else:
            legal_sources = response_data.get("legal_sources", [])
            if not legal_sources:
                lines.append("Aucun texte juridique cit√©.\n")
            else:
                for art in legal_sources:
                    lines.append(f"- Article {getattr(art, 'num', 'N/A')} ({getattr(art, 'collection', 'N/A')})\n")
                    if getattr(art, "titre", None):
                        lines.append(f"  Titre: {art.titre}\n")
                    contenu = art.article_complet if hasattr(art, 'article_complet') else getattr(art, 'contenu', '')
                    lines.append("  Texte:\n" + str(contenu) + "\n\n")

    return "\n".join(str(x) for x in lines)

# Fonction qui construit un objet RetrievedLegalDocument √† partir d'un payload Qdrant
def make_retrieved_document(payload: dict, uid: str, collection: str, score: float = 0) -> RetrievedLegalDocument:
    """Construit un objet RetrievedLegalDocument √† partir d'un payload Qdrant."""
    return RetrievedLegalDocument(
        chunk_id=uid,
        num=payload.get("num", ""),
        titre=payload.get("titre", ""),
        contenu=payload.get("contenu", ""),
        article_complet=payload.get("article_complet", payload.get("contenu", "")),
        contexte_hierarchique=payload.get("contexte_hierarchique", ""),
        collection=collection,
        partie=payload.get("partie"),
        livre=payload.get("livre"),
        titre_structure=payload.get("titre_structure"),
        chapitre=payload.get("chapitre"),
        section=payload.get("section"),
        sous_section=payload.get("sous_section"),
        paragraphe=payload.get("paragraphe"),
        sous_paragraphe=payload.get("sous_paragraphe"),
        base_legislative=payload.get("base_legislative", []),
        score=score
    )

# Fonction qui recherche des articles juridiques dans les collections Qdrant en utilisant des embeddings
def search_articles(
    query: str,
    partie: Optional[str] = None,
    limit: int = 5,
    must_contain: Optional[str] = None,
    debug: bool = False,
    threshold: float = 0.0
) -> Dict[str, Any]:
    """Recherche optimis√©e d'articles juridiques dans Qdrant."""
    target_collections = ["CASF", "Code du travail", "Code de la sant√© publique", "Code de la s√©curit√© sociale"]
    collections = qdrant_client.get_collections()
    valid_collections = [c.name for c in collections.collections if c.name in target_collections]

    if not valid_collections:
        return {"sources": [], "total": 0, "limit": limit, "offset": 0}

    try:
        # Recherche vectorielle
        embedding = embedding_model.encode(query).tolist()
        query_filter = models.Filter(
            must=[models.FieldCondition(key="partie", match=models.MatchValue(value=partie))]
        ) if partie else None

        all_results = []
        for collection in valid_collections:
            try:
                hits = qdrant_client.search(
                    collection_name=collection,
                    query_vector=embedding,
                    query_filter=query_filter,
                    limit=limit,
                    with_payload=True,
                    with_vectors=False
                )
                all_results.extend(hits)
            except Exception as e:
                continue

        # Filtrage par score
        results = [r for r in all_results if r.score >= threshold]

        # Filtrage par mot-cl√©
        if must_contain:
            results = [
                r for r in results
                if must_contain.lower() in r.payload.get("contenu", "").lower()
            ]

        if not results:
            return {"sources": [], "total": 0, "limit": limit, "offset": 0}

        # Mapping vers RetrievedLegalDocument
        documents: List[RetrievedLegalDocument] = []
        for result in results:
            try:
                # Utilise payload["chunk_id"] (str) au lieu de result.id (int/UUID)
                chunk_id = result.payload.get("chunk_id")  # Ex: "L111-1_chunk0"
                if not chunk_id:
                    chunk_id = result.payload.get("uid", str(result.id))  # Fallback pour les collections sans chunk_id
                article = make_retrieved_document(
                    payload=result.payload,
                    uid=chunk_id,  # ‚Üê Ici, chunk_id est TOUJOURS une cha√Æne
                    collection=result.payload.get("collection", ""),
                    score=result.score
                )
                documents.append(article)
            except Exception as e:
                continue

        # D√©duplication par num√©ro
        seen = set()
        unique_documents = []
        for doc in documents:
            if doc.num not in seen:
                seen.add(doc.num)
                unique_documents.append(doc)

        # Tri par num√©ro
        unique_documents.sort(key=lambda d: d.num)

        return {
            "sources": unique_documents[:limit],
            "total": len(unique_documents),
            "limit": limit,
            "offset": 0
        }

    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"sources": [], "total": 0, "limit": limit, "offset": 0}

# Fonction pour construire un arbre l√©gislatif
def build_legislative_tree(sources: List[RetrievedLegalDocument]) -> Dict[str, Any]:
    """
    Version corrig√©e qui:
    1. √âvite de modifier le dictionnaire pendant l'it√©ration
    2. Utilise une copie des cl√©s pour l'it√©ration
    3. Conserve tous les logs et la structure uniforme
    """

    # 1. Ajouter tous les articles sources (d√©j√† des objets)
    enrichis = {}
    for art in sources:
        enrichis[art.num] = {
            "article": art,
            "parents": [],
            "enfants": [],
            "type": art.num[0] if art.num else "?"
        }

    # 2. Pour chaque article source, r√©cup√©rer les articles de m√™me groupe hi√©rarchique
    for art in sources:
        # Priorit√© des niveaux hi√©rarchiques (du plus pr√©cis au plus g√©n√©ral)
        hierarchy_levels = [
            ("sous_paragraphe", art.sous_paragraphe),
            ("paragraphe", art.paragraphe),
            ("sous_section", art.sous_section),
            ("section", art.section),
            ("chapitre", art.chapitre)
        ]

        for level_key, level_value in hierarchy_levels:
            if not level_value:
                continue

            try:
                flt = models.Filter(
                    must=[
                        models.FieldCondition(
                            key=level_key,
                            match=models.MatchText(text=level_value)
                        ),
                        models.FieldCondition(
                            key="collection",
                            match=models.MatchValue(value=art.collection)
                        )
                    ]
                )

                points, _ = qdrant_client.scroll(
                    collection_name=art.collection,
                    scroll_filter=flt,
                    limit=100,
                    with_payload=True,
                    with_vectors=False,
                )

                for point in points:
                    payload = point.payload
                    art_num = payload.get("num")
                    if not art_num or art_num in enrichis:
                        continue

                    new_art = make_retrieved_document(
                        payload=payload,
                        uid=payload.get("chunk_id", str(point.id)),
                        collection=payload.get("collection", art.collection),
                        score=0
                    )
                    enrichis[art_num] = {
                        "article": new_art,
                        "parents": [],
                        "enfants": [],
                        "type": art_num[0] if art_num else "?"
                    }

                break

            except Exception as e:
                continue

    # 3. Gestion des r√©f√©rences (base_legislative) pour TOUS les articles
    # ‚úÖ Solution: It√©rer sur une COPIE des cl√©s pour √©viter de modifier le dict pendant l'it√©ration
    for art_uid in list(enrichis.keys()):  # ‚Üê COPIE des cl√©s !
        art_data = enrichis[art_uid]
        art = art_data["article"]

        for ref in art.base_legislative or []:
            ref_uid = ref.uid if hasattr(ref, 'uid') else ref.get('uid')
            if not ref_uid or ref_uid in enrichis:
                continue

            try:
                ref_collection = ref.collection if hasattr(ref, 'collection') else art.collection

                ref_points, _ = qdrant_client.scroll(
                    collection_name=ref_collection,
                    scroll_filter=models.Filter(
                        must=[models.FieldCondition(
                            key="num",
                            match=models.MatchValue(value=ref_uid)
                        )]
                    ),
                    limit=1,
                    with_payload=True,
                    with_vectors=False,
                )

                if ref_points:
                    ref_payload = ref_points[0].payload
                    ref_art = make_retrieved_document(
                        payload=ref_payload,
                        uid=ref_payload.get("chunk_id", str(ref_points[0].id)),
                        collection=ref_payload.get("collection", ref_collection),
                        score=0
                    )
                    enrichis[ref_uid] = {  # ‚úÖ Ajout d'un nouvel √©l√©ment au dict
                        "article": ref_art,
                        "parents": [],
                        "enfants": [],
                        "type": ref_uid[0] if ref_uid else "?"
                    }

                    # Ajout des relations parent/enfant
                    art_data["parents"].append(enrichis[ref_uid]["article"])
                    enrichis[ref_uid]["enfants"].append(art_data["article"])

            except Exception as e:
                continue

    return enrichis

# Fonction de tri des num√©ros
def sort_key_num(article_data: Dict[str, Any]) -> tuple:
    """Cl√© de tri pour les num√©ros d'article (ex: L241-3)."""
    num = article_data["article"].num  # Acc√®s direct √† l'attribut Pydantic
    m = re.match(r"[LRD](\d+)(?:-(\d+))?", num)
    if m:
        base = int(m.group(1))
        suffix = int(m.group(2)) if m.group(2) else 0
        return (base, suffix)
    return (float("inf"), float("inf"))

# Fonction qui ajoute un article dans l'arbre partag√© selon les niveaux hi√©rarchiques
def add_to_tree(tree: dict, article: RetrievedLegalDocument, item: dict):
    """
    Ajoute un article dans l'arbre hi√©rarchique avec ses relations.
    - article: Objet RetrievedLegalDocument (pour la hi√©rarchie)
    - item: Dictionnaire COMPLET avec parents/enfants (pour les relations)
    """
    # Construire la hi√©rarchie depuis les champs de l'article
    levels = [
        article.collection,
        article.partie,
        article.livre,
        article.titre_structure,
        article.chapitre,
        article.section,
        article.sous_section,
        article.paragraphe,
        article.sous_paragraphe,
    ]
    # Filtrer les niveaux vides
    levels = [lvl for lvl in levels if lvl]

    # Naviguer dans l'arbre
    node = tree
    for label in levels:
        node = node.setdefault(label, {})

    # Ajouter l'article AVEC SES RELATIONS
    node.setdefault("_items", []).append(item)  # ‚úÖ item contient parents/enfants

# Fonction qui affiche r√©cursivement l'arbre sous forme d'expanders
def render_tree(container, node: dict, level: int = 0):
    """
    Version simplifi√©e qui affiche :
    1. Tous les articles dans une arborescence unique
    2. Pour chaque article : uniquement "R√©f√©renc√© par" et "Articles cit√©s"
    """
    # Styles CSS
    container.markdown("""
    <style>
        .article-title { font-weight: bold; margin-bottom: 5px; }
        .article-body { font-size: 14px; line-height: 1.4; margin-bottom: 10px; }
        .relation-section { margin-top: 10px; margin-bottom: 10px; }
        .relation-title { font-weight: bold; color: #333; }
        .relation-item { margin-left: 15px; color: #555; }
    </style>
    """, unsafe_allow_html=True)

    # Affichage des articles avec tri num√©rique
    for data in sorted(node.get("_items", []),
                      key=lambda x: [
                          int(part) if part.isdigit() else part
                          for part in x["article"].num.split('-')
                      ]):
        art = data["article"]

        with container.expander(f"üìú {art.num} - {art.titre}"):
            # Contenu de l'article
            container.markdown(f'<div class="article-body">{art.article_complet}</div>', unsafe_allow_html=True)

            # Section "R√©f√©renc√© par" (anciennement "Enfants")
            if data.get("enfants"):
                container.markdown('<div class="relation-section">'
                                   '<div class="relation-title">üë∂ R√©f√©renc√© par :</div>', unsafe_allow_html=True)
                for enfant in data["enfants"]:
                    container.markdown(f'<div class="relation-item">- {enfant.num} : {enfant.titre}</div>',
                                      unsafe_allow_html=True)

            # Section "Articles cit√©s" (anciennement "Parents")
            if data.get("parents"):
                container.markdown('<div class="relation-section">'
                                   '<div class="relation-title">üìö Articles cit√©s :</div>', unsafe_allow_html=True)
                for parent in data["parents"]:
                    container.markdown(f'<div class="relation-item">- {parent.num} : {parent.titre}</div>',
                                      unsafe_allow_html=True)

    # Navigation hi√©rarchique (uniquement pour l'organisation visuelle)
    for label, child in sorted(((k, v) for k, v in node.items() if k != "_items"), key=lambda x: x[0]):
        with container.expander(f"üìÅ {label}"):
            render_tree(container, child, level + 1)

# Fonction de recherches de documents dans tout le RAG (hors codes et jeu de donn√©es QE) pour alimenter l'API
def search_uploaded_documents(
    query: str,
    qdrant_client: Any,
    embedding_model: Any,
    selected_collections: List[str] = None,
    top_k: int = 3,
    top_k_selected = 10,
) -> List[Dict]:
    """
    Recherche dans les collections-documents (1 collection = 1 document).
    Args:
        query: Requ√™te de recherche.
        qdrant_client: Client Qdrant.
        embedding_model: Mod√®le d'embedding.
        selected_collections: Liste des collections √† rechercher (optionnel).
        top_k: Nombre de r√©sultats max si aucune collection s√©lectionn√©e.
        top_k_selected: Nombre de r√©sultats max si collections s√©lectionn√©es.
    Returns:
        Liste de dicts avec les champs essentiels.
    """
    query_embedding = embedding_model.encode(query).tolist()
    all_results = []
    try:
        # 1. R√©cup√®re les collections √† rechercher
        protected = {
            "QuestionParlementaire",
            "Code de la s√©curit√© sociale",
            "Code du travail",
            "CASF",
            "Code de la sant√© publique",
        }
        collections = qdrant_client.get_collections()
        doc_collections = [col.name for col in collections.collections if col.name not in protected]

        # 2. Limite aux collections s√©lectionn√©es si sp√©cifi√©es
        if selected_collections:
            doc_collections = [col for col in doc_collections if col in selected_collections]
            # le nombre de chunks retourn√©s passe √† 10 si la recherche est limit√© sur une ou plusieurs collections
            top_k = top_k_selected
            if not doc_collections:
                doc_collections = [col for col in doc_collections if col not in protected]
            
        # 3. Recherche dans chaque collection-document
        for collection in doc_collections:
            try:
                results = qdrant_client.search(
                    collection_name=collection,
                    query_vector=query_embedding,
                    limit=top_k,
                    with_payload=True,
                    with_vectors=False,
                )
                for result in results:
                    payload = result.payload or {}
                    all_results.append({
                        "collection": collection,
                        "text": payload.get("text", ""),
                        "score": float(result.score) if hasattr(result, "score") else None,
                        "title": payload.get("section"),
                    })
            except Exception as e:
                st.warning(f"Erreur sur {collection}: {e}")

        # 4. Trie par score et limite les r√©sultats
        all_results.sort(key=lambda x: (x["score"] is not None, x["score"]), reverse=True)
        return all_results[:top_k]

    except Exception as e:
        st.error(f"Erreur de recherche dans les documents upload√©s: {e}")
        return []

# Fonction qui ajuste la taille du contexte issu des "autres collections" √† la pertinence (score) du retrieval
def format_uploaded_docs_by_relevance(
    uploaded_results: List[Dict],
    min_score: float = 0.7,
    max_docs: int = 3,
    max_length: int = 400
) -> str:
    """
    Trie les r√©sultats par score et formate les extraits textuels pour enrichir le prompt.
    - uploaded_results : liste de dictionnaires renvoy√©s par la recherche vectorielle
    - min_score : seuil de pertinence minimum
    - max_docs : nombre maximum de documents √† inclure
    - max_length : longueur maximale de l'extrait
    """
    if not uploaded_results:
        return ""

    # Filtrer par score
    filtered = [doc for doc in uploaded_results if doc.get("score", 0) >= min_score]

    # Trier par score d√©croissant
    filtered.sort(key=lambda d: d.get("score", 0), reverse=True)

    # Limiter le nombre de docs
    filtered = filtered[:max_docs]

    formatted = []
    for doc in filtered:
        passage = doc.get("text", "")
        source = doc.get("collection", "inconnu").replace("_", " ")
        title = doc.get("title", "") or ""
        score = doc.get("score", 0)

        formatted.append(
            f"Source: {source} (Section: {title})\n"
            f"Passage: {passage[:max_length]}...\n"
            f"(Score: {score:.2f})\n"
        )

    return "\n---\n".join(formatted)

# Fonction de recherches d'anciennes questions / r√©ponses dans le RAG Qdrant
def search_question_parlementaire(query: str, top_k: int = 5) -> List[ResponseDocument]:
    embedding = embedding_model.encode(query).tolist()
    hits = qdrant_client.search(
        collection_name="QuestionParlementaire",
        query_vector=embedding,
        limit=top_k,
        with_payload=True,
        with_vectors=False
    )
    results: List[ResponseDocument] = []

    for i, r in enumerate(hits):
        p = r.payload or {}
        try:
            # Normalisation s√©curis√©e des champs
            uid = str(p.get("uid", "")) if p.get("uid") is not None else ""
            legislature = str(p.get("legislature")) if p.get("legislature") is not None else None
            ministeres = p.get("ministeres_attribues")
            if isinstance(ministeres, str):
                ministeres = [ministeres]
            elif not isinstance(ministeres, list):
                ministeres = []
            textes_juridiques = p.get("textes_juridiques")
            if isinstance(textes_juridiques, str):
                textes_juridiques = [textes_juridiques]
            elif not isinstance(textes_juridiques, list):
                textes_juridiques = []

            # Cr√©ation du document
            doc = ResponseDocument(
                uid=uid,
                question=p.get("question", ""),
                reponse=p.get("reponse", ""),
                legislature=legislature,
                chambre=p.get("chambre"),
                rubrique=p.get("rubrique"),
                analyse=p.get("analyse"),
                ministeres_attribues=ministeres,
                date_question=p.get("date_question"),
                date_reponse=p.get("date_reponse"),
                textes_juridiques=textes_juridiques,
                score=r.score
            )
            results.append(doc)

        except Exception as e:
             continue  # Passe au r√©sultat suivant

    return results

# Fonction qui extrait un ordre num√©rique √† partir d'un label en chiffres romains
ROMAN_MAP = {
    "I":1,"II":2,"III":3,"IV":4,"V":5,"VI":6,"VII":7,"VIII":8,"IX":9,"X":10,
    "XI":11,"XII":12,"XIII":13,"XIV":14,"XV":15,"XVI":16,"XVII":17,"XVIII":18,"XIX":19,"XX":20
}
def extract_order(label: str) -> int:
    if not label:
        return float("inf")
    m_roman = re.search(r"\b(Ier|[IVXLCDM]+)\b", label)
    if m_roman:
        return 1 if m_roman.group(1) == "Ier" else ROMAN_MAP.get(m_roman.group(1), float("inf"))
    m_num = re.search(r"\b(\d+)\b", label)
    if m_num:
        return int(m_num.group(1))
    return float("inf")

# Construit un prompt pour Mistral Large afin de g√©n√©rer une analyse juridique.
def build_legal_analysis_prompt(question: str, articles: List[RetrievedLegalDocument], stats: dict) -> str:
    # Construit un prompt pour Mistral Large afin de g√©n√©rer une analyse juridique.
    # Pr√©paration des articles sous forme de contexte avec troncature brute
    max_chars = 70000  # limite totale pour les articles (‚âà 3500-4000 tokens)
    articles_context = []
    total_chars = 0

    for article in articles:
        uid = article.num
        titre = article.titre
        contenu = article.article_complet  # ou article.contenu selon votre besoin

        if total_chars + len(contenu) > max_chars:
            # Tronquer le dernier article pour ne pas d√©passer la limite
            allowed = max_chars - total_chars
            truncated = contenu[:allowed]
            articles_context.append(f"### Article {uid}: {titre}\n{truncated}\n[Texte tronqu√©]\n")
            break
        else:
            articles_context.append(f"### Article {uid}: {titre}\n{contenu}\n")
            total_chars += len(contenu)

    articles_str = "\n".join(articles_context)

    # Consignes pour Mistral
    prompt = f"""
    [INST]
    **Consignes strictes pour une analyse juridique compl√®te :**
    1. **Structure obligatoire** √† respecter imp√©rativement :
       - Introduction (50-100 mots) : rappel du contexte juridique de la question
       - Analyse d√©taill√©e (80-90% du contenu) :
         * L'analyse doit √™tre faite exclusivement √† partir des articles suivants : {articles_str}
         * Pr√©sentation des principes g√©n√©raux avec citations pr√©cises d'un maximum d'articles
         * Pr√©sentation des enjeux
       - Conclusion synth√©tique (100-150 mots)
       - Toute r√©ponse qui se termine par une phrase tronqu√©e sera consid√©r√©e comme irrecevable

    2. **Exigences de compl√©tude** :
       - Toute phrase doit √™tre grammaticalement compl√®te
       - La derni√®re phrase doit imp√©rativement r√©sumer un point cl√©
       - Si le d√©veloppement d√©passe la limite, prioriser :
         1. Les principes fondamentaux
         2. Les exceptions majeures
         3. Un exemple concret d'application

    3. **Style requis** :
       - Style tr√®s concis
       - Phrases courtes (20-25 mots max)
       - Un paragraphe = une id√©e juridique pr√©cise
       - Citations syst√©matiques des articles (ex: "L'article R241-12 pr√©cise que...")
       - √âviter les formules vagues ("certains cas", "parfois") ‚Üí pr√©ciser les conditions

    **Question √† analyser** :
    {question}

    [/INST]
    """
    return prompt

# Appelle l'API Mistral Large pour g√©n√©rer une analyse juridique ##### 4000 TOKENS DEFINIS ICI ######
def call_mistral_legal_analysis(
    prompt: str,
    max_tokens: int = 4000,
    temperature: float = 0.3,
    model_size: str = "small"  # "large", "medium", "small"
):
    # Appelle l'API Mistral avec chainage automatique pour les r√©ponses tronqu√©es.
    mistral_api_url = "https://api.mistral.ai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY}",
        "Content-Type": "application/json"
    }

    # Construire le nom du mod√®le dynamiquement
    model_name = f"mistral-{model_size}-latest"

    def is_complete(response_text):
        # V√©rifie si une r√©ponse est grammaticalement compl√®te
        if not response_text:
            return False

        last_char = response_text[-1]
        last_sentence = response_text.split('.')[-1].strip()

        return (
            (last_char in ('.', '!', '?')) and
            (len(last_sentence.split()) > 3) and
            (not last_sentence.endswith((':', ';', ','))) and
            (not response_text.endswith(('...', '‚Äì', '‚Äî')))
        )

    def complete_response(truncated_response):
        # Termine une r√©ponse tronqu√©e
        completion_prompt = f"""
        [INST]
        Terminez cette analyse juridique de mani√®re compl√®te et professionnelle.
        Analyse en cours: "{truncated_response[-500:]}"  # Derniers 500 caract√®res

        Consignes strictes:
        1. R√©sumez en 1 phrase le point juridique en cours
        2. Ajoutez 2-3 phrases de conclusion qui:
           - Synth√©tisent les points cl√©s
           - Proposent une application pratique
           - Se terminent imp√©rativement par un point
        3. Utilisez un style formel: "En cons√©quence...", "Ainsi, il ressort que...", etc.
        [/INST]
        """

        try:
            completion_response = requests.post(
                mistral_api_url,
                headers=headers,
                json={
                    "model": model_name,  # <-- correction ici
                    "messages": [{"role": "user", "content": completion_prompt}],
                    "max_tokens": 500,
                    "temperature": 0.2,
                    "stop": ["."]  
                },
                timeout=30
            )
            completion_response.raise_for_status()
            completion = completion_response.json()["choices"][0]["message"]["content"].strip()

 #            if is_complete(completion):
            return truncated_response + "\n\n" + completion
 #            else:
 #                return truncated_response + "\n\nCette analyse couvre succinctement les principaux aspects juridiques de la question pos√©e."

        except Exception as e:
            return truncated_response + f"\n\n[Note: La conclusion de cette analyse a √©t√© synth√©tis√©e. Erreur technique: {str(e)}]"

    try:
        response = requests.post(
            mistral_api_url,
            headers=headers,
            json={
                "model": model_name,  # <-- correction ici aussi
                "messages": [{"role": "user", "content": prompt}],
                "temperature": temperature,
                "max_tokens": max_tokens,
                "top_p": 0.9,
                "frequency_penalty": 0.1,
                "presence_penalty": 0.1
            },
            timeout=120
        )
        response.raise_for_status()
        data = response.json()
        analysis = data["choices"][0]["message"]["content"].strip()

        if not is_complete(analysis):
            analysis = complete_response(analysis)

        return analysis

    except requests.exceptions.RequestException as e:
        return f"Erreur lors de l'appel √† l'API Mistral: {str(e)}"

# Fonction de g√©n√©ration d'analyse juridique
def generate_legal_analysis(
    question: str,
    must_contain: str = "",
    max_articles: int = 5,
    threshold: float = 0.5,
    model_size: str = "small",
    search_button: bool = False,
    generate_analysis_button: bool = False
) -> dict:
    try:
        import sys
        from io import StringIO
        old_stdout = sys.stdout
        sys.stdout = captured_output = StringIO()

        # Recherche des articles (avec cache)
        if "last_articles_search" not in st.session_state or search_button:
            st.session_state.last_articles_search = search_articles(
                query=question,
                limit=max_articles,
                must_contain=must_contain if must_contain else None,
                debug=True,
                threshold=threshold
            )
        articles = st.session_state.last_articles_search

        # Pr√©paration des sources enrichies
        enrichis = build_legislative_tree(articles["sources"])
        stats = enrichis.pop('stats', {})

        # Formatage des sources pour l'affichage et l'analyse
        sources = []
        for uid, data in enrichis.items():
            if isinstance(data, dict) and "article" in data:
                sources.append({
                    "uid": uid,
                    "article": data["article"],
                    "type": data.get("type"),
                    "parents": data.get("parents", []),
                    "enfants": data.get("enfants", [])
                })

        # Fallback si aucun enrichissement
        if not sources:
            sources = [{
                "uid": art.num,
                "article": art,
                "type": art.num[0] if art.num else "?",
                "parents": [],
                "enfants": []
            } for art in articles["sources"]]

        # Gestion des cas d'erreur
        if not sources or len(sources) == 0:
            st.warning("Aucun article juridique valide apr√®s traitement.")
            return {
                "response": "Aucun article juridique valide apr√®s traitement.",
                "sources": [],
                "similar_documents": [],
                "debug_logs": captured_output.getvalue(),
                "stats": stats
            }

        # Mode "Recherche" (affichage des articles)
        if search_button:
            return {
                "response": "Voir les articles dans l'onglet sources.",
                "sources": sources,
                "similar_documents": [],
                "debug_logs": captured_output.getvalue(),
                "stats": stats
            }

        # Mode "G√©n√©ration" (appel √† Mistral)
        elif generate_analysis_button:
            prep_placeholder = st.empty()
            prep_placeholder.markdown(
                '''
                <div class="prep-message">
                    üîß Production de l'analyse en cours<span id="dots">...</span>
                </div>
                <script>
                    const dots = document.getElementById('dots');
                    let dotCount = 0;
                    const interval = setInterval(() => {
                        dotCount = (dotCount + 1) % 4;
                        dots.textContent = '.'.repeat(dotCount);
                    }, 500);
                </script>
                ''',
                unsafe_allow_html=True
            )

            # Appel √† Mistral avec les articles originaux (non enrichis)
            prompt = build_legal_analysis_prompt(question, articles["sources"], stats)
            legal_analysis = call_mistral_legal_analysis(
                prompt,
                max_tokens=4000,
                temperature=0.3,
                model_size=model_size
            )

            # Efface le message de chargement
            prep_placeholder.empty()

            return {
                "response": legal_analysis,
                "sources": sources,  # Sources enrichies pour l'affichage
                "similar_documents": [],
                "debug_logs": captured_output.getvalue(),
                "stats": stats
            }

    finally:
        sys.stdout = old_stdout

# Construit le prompt d'appel √† Mistral
def build_parlementary_response_prompt(
    question: str,
    parliamentary_context: str,
    legal_context: str,
    uploaded_documents: str,
    detail_juridique: int,
    longueur: str,
    response_orientation: str,
    custom_instructions: str,
    search_context: str
) -> str:
    # Construit un prompt optimis√© avec contexte parlementaire ET juridique.
    # Mapping des orientations de r√©ponse

    orientation_mapping = {
        "R√©pondre de fa√ßon neutre":
            "Adoptez un ton neutre et factuel. "
            "Commencez par **souligner l'importance du sujet** pour le Gouvernement, sans reprendre les termes critiques du parlementaire. "
            "Utilisez des formulations comme : "
            "'Ce sujet est une priorit√© pour le Gouvernement, comme en t√©moignent [mesures existantes]', "
            "'Le Gouvernement est pleinement conscient des enjeux li√©s √† [th√®me]', "
            "'Cette question, essentielle pour [public concern√©], fait l'objet d'une attention constante de la part des services de l'√âtat'. "
            "√âvitez absolument les formulations du type : 'comme vous le soulignez √† juste titre', 'vous avez raison de pointer', ou 'la situation est effectivement pr√©occupante'. "
            "Privil√©giez les faits, les chiffres, et les actions en cours.",

        "R√©pondre n√©gativement aux propositions du parlementaire":
            "R√©pondez de mani√®re **polie mais ferme**, en **recentrant le d√©bat sur les actions du Gouvernement** plut√¥t que sur les critiques. "
            "Structurez votre r√©ponse ainsi : "
            "1. **Reconnaissez l'importance du sujet** (sans valider les critiques) : "
            "'La question que vous soulevez touche √† un enjeu majeur pour [public concern√©], auquel le Gouvernement apporte une r√©ponse structur√©e.' "
            "2. **Rappelez le cadre existant** : "
            "'Conform√©ment √† [texte juridique ou politique publique], les actions men√©es visent √† [objectif].' "
            "3. **Expliquez les contraintes** (si n√©cessaire) : "
            "'Les marges de man≈ìuvre sont encadr√©es par [contrainte l√©gale/budg√©taire], mais le Gouvernement agit dans le respect de ces r√®gles pour [objectif].' "
            "4. **Mettez en avant les alternatives ou mesures en cours** : "
            "'Plut√¥t que [proposition du parlementaire], le Gouvernement a choisi de [mesure alternative], qui permet de [b√©n√©fice].' "
            "Exemple : 'Plut√¥t qu‚Äôune refonte compl√®te du dispositif, nous avons renforc√© [mesure X], qui a d√©j√† permis [r√©sultat].' "
            "√âvitez les formulations d√©fensives comme 'nous ne pouvons pas' ‚Äì pr√©f√©rez 'notre approche privil√©gie [solution], car [raison].'",

        "R√©pondre positivement aux propositions du parlementaire":
            "Saluiez l‚Äôint√©r√™t de la proposition **sans reprendre les critiques sous-jacentes**. "
            "Utilisez des formulations comme : "
            "'Votre proposition s‚Äôinscrit dans une dynamique que le Gouvernement partage, comme en attestent [mesures existantes].' "
            "'Nous partageons votre pr√©occupation pour [enjeu], et nos actions vont dans le sens de [objectif], comme le montre [exemple].' "
            "√âvitez : 'Vous avez raison de souligner que...' ‚Üí pr√©f√©rez : 'Votre attention √† ce sujet rejoint nos priorit√©s, illustr√©es par [action].'",

        "R√©pondre de mani√®re technique et d√©taill√©e":
            "Fournissez une r√©ponse **factuelle et technique**, en √©vitant tout commentaire sur les critiques du parlementaire. "
            "Structurez ainsi : "
            "1. **Cadre juridique** : 'Le dispositif actuel, d√©fini par [article X], repose sur [principe].' "
            "2. **Donn√©es chiffr√©es** : 'Les derniers chiffres (source : [DREES/INSEE/...], [ann√©e]) montrent que [tendance].' "
            "3. **Mesures en cours** : 'Pour r√©pondre √† ces enjeux, [mesure A] et [mesure B] ont √©t√© mises en place, avec [r√©sultat].' "
            "Utilisez un vocabulaire neutre et des verbes d‚Äôaction : 'le Gouvernement a engag√©', 'les services travaillent √†', 'les r√©sultats montrent que'."
    }

    # Longueur maximale selon le param√®tre
    max_tokens = 500 if longueur.startswith("Courte") else 1000 if longueur.startswith("Moyenne") else 2200

    # Construction du prompt
    prompt = f"""
    [INST]
    {orientation_mapping.get(response_orientation, "")}

    **Question parlementaire :**
    {question}

    **Contexte parlementaire (r√©ponses similaires pass√©es) :**
    {parliamentary_context}

    **Textes juridiques applicables (PRIORITAIRES) :**
    {legal_context}

    **Documents de r√©f√©rence upload√©s (trait√©s avec vos fonctions d'extraction) :**
    {uploaded_documents}

    **R√©sultats de recherche internet (actualit√©s, positions du gouvernement) :**
    {search_context}

    **Consignes strictes :**
    1. **Priorit√© juridique** : Votre r√©ponse DOIT √™tre coh√©rente avec les textes juridiques fournis.
       En cas de contradiction entre le contexte parlementaire et les textes juridiques, priorisez ces derniers.
       En cas de contradiction entre le contexte parlementaire et les r√©sultats de recherche internet, priorisez ces derniers.
       Citez explicitement les articles pertinents (ex: "comme le pr√©cise l'article L124-5 du CASF...").

    2. **Structure** :
       - Reconna√Ætre l'importance du sujet sans insister sur les difficult√©s soulev√©es par le parlementaire, surtout si elles sont critiques quant √† l'action du Gouvernement
       - Rappelez √©ventuellement les chiffres et le cadre juridique
       - Poursuivez avec les √©l√©ments budgetaires
       - Int√©grez les informations issues prioritairement des documents de r√©f√©rence upload√©s puis de la recherche internet de mani√®re fluide, sans mention explicite de la source ("recherche internet", "r√©sultats de recherche") pour :
            - d√©crire les mesures prises par le Gouvernement et celles sur lesquelles le Gouvernement travaille
            - pr√©ciser la position du Gouvernement sur le sujet principal de la question parlementaire
       - Ne pas annoncer d'√©ch√©ances √† venir pour des dates ant√©rieures √† la date du jour (exemple : "Une concertation sera men√©e d‚Äôici l‚Äô√©t√© 2024" alors que nous sommes en novembre 2025)
       - Concluez en r√©affirmant l'engagement du Gouvernement.
       - Ne pas m√©langer le sujet √† d'autres sujets trop √©loign√©s dans la conclusion.

    3. **Niveau de d√©tail** : {detail_juridique}/5 (adaptez la profondeur des explications juridiques).

    4. **Longueur et ajustement dynamique** :
       - Limite absolue : {max_tokens} tokens.
       - Avant de finaliser, estimez le nombre de tokens de votre r√©ponse.
       - Si vous d√©passez {max_tokens} :
            - Supprimez les exemples, les r√©p√©titions ou les donn√©es secondaires.
            - Conservez imp√©rativement : l‚Äôenjeu, le cadre juridique, et la conclusion.
            - Utilisez des formulations comme : "Pour respecter la limite, nous synth√©tisons les points cl√©s :"
       - Si la r√©ponse risque d‚Äô√™tre trop courte, d√©veloppez le cadre juridique ou les mesures en cours.

    5. **Estimation pr√©alable** :
       - Un paragraphe = ~100 tokens. Adaptez le nombre de paragraphes en cons√©quence.
       - Apr√®s chaque section, v√©rifiez que le total reste inf√©rieur √† {max_tokens}.

    6. **Style** :
       - Utilisez un style administratif, formel et concis, comme dans les r√©ponses minist√©rielles.
       - La r√©ponse doit √™tre r√©dig√©e en prose continue, sans titres, sans puces, sans num√©rotation.
       - R√©pondez pr√©cis√©ment aux questions pos√©es, par exemple sur les √©l√©ments budg√©taires ou de calendrier.
       - La r√©ponse doit √™tre d'actualit√© et privil√©gier les informations les plus r√©centes.
       - Si les propositions faites par le parlementaire sont int√©ressantes, dites qu'elles seront √©tudi√©es.
       - Utilisez uniquement des paragraphes r√©dig√©s, comme dans les r√©ponses minist√©rielles publi√©es au Journal Officiel.
       - Si vous avez plusieurs √©l√©ments √† pr√©senter, int√©grez-les dans des phrases compl√®tes reli√©es par des connecteurs ("par ailleurs", "en outre", "de plus").
       - Les √©l√©ments de la r√©ponse ne doivent pas √™tre redondants.
       - Ne pas mettre de formule de politesse √† la fin.
       - **Contrainte de longueur absolue** : La r√©ponse ne doit pas d√©passer {longueur}.
       - Toute r√©ponse plus longue sera rejet√©e.
       - Si le sujet est trop complexe pour tenir dans cette limite, concentrez-vous sur les points les plus importants.
       - Toute r√©ponse qui se termine par une phrase tronqu√©e est incorrecte.
       - Toute r√©ponse qui contient des listes ou des titres est incorrecte.

    {f"7. Instructions sp√©cifiques strictes : {custom_instructions}" if custom_instructions else ""}
    [/INST]
    """
    return prompt

# Appelle l'API Mistral Large pour g√©n√©rer une r√©ponse parlementaire
def call_mistral_parlementary_response(
    prompt: str,
    longueur: str,
    question: str,
    max_retries: int = 2,
    model_size: str = "small"   # "large", "medium", "small"
) -> str:
    # Appelle l'API Mistral pour g√©n√©rer une r√©ponse parlementaire. Le mod√®le est choisi dynamiquement (small, medium, large).
    mistral_api_url = "https://api.mistral.ai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY}",
        "Content-Type": "application/json"
    }

    # Construire le nom du mod√®le dynamiquement
    model_name = f"mistral-{model_size}-latest"

    # D√©terminer la taille de sortie en fonction de la longueur souhait√©e
    if longueur.startswith("Courte"):
        max_tokens = 500
    elif longueur.startswith("Moyenne"):
        max_tokens = 1000
    else:
        max_tokens = 2200

    # V√©rifier la taille du prompt
    prompt_tokens = estimate_tokens(prompt)
    if prompt_tokens > 30000:
        raise ValueError(f"Prompt trop long: {prompt_tokens} tokens (limite: 30000)")

    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.3,
        "max_tokens": max_tokens
    }

    for attempt in range(max_retries):
        try:
            response = requests.post(mistral_api_url, headers=headers, json=payload, timeout=90)
            response.raise_for_status()
            data = response.json()

            mistral_response = data["choices"][0]["message"]["content"]
            is_truncated = data["choices"][0].get("finish_reason") == "length"

            if is_truncated:
                try:
                    mistral_response = handle_truncated_response(mistral_response, question, longueur)
                except Exception as e:
                    raise Exception(f"Erreur lors de la compl√©tion de la r√©ponse tronqu√©e: {str(e)}")

            return mistral_response

        except requests.exceptions.HTTPError as e:
            if response.status_code == 429 and attempt < max_retries - 1:  # Too Many Requests
                st.warning(f"‚è≥ API Mistral temporairement encombr√©e. Tentative {attempt + 1}/{max_retries}. Relance dans 10 secondes...")
                time.sleep(10)
            else:
                raise Exception(f"Erreur HTTP {response.status_code}: {str(e)}")

        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                st.warning(f"‚ö†Ô∏è Erreur r√©seau. Tentative {attempt + 1}/{max_retries}. Relance dans 10 secondes...")
                time.sleep(10)
            else:
                raise Exception(f"Erreur r√©seau: {str(e)}")

# Compl√®te une r√©ponse tronqu√©e
def handle_truncated_response(response: str, question: str, longueur: str) -> str:
    # G√®re les r√©ponses tronqu√©es par Mistral.
    last_period = response.rfind('.')
    if last_period > 0 and last_period < len(response) - 100:
        incomplete_part = response[last_period+1:]
    else:
        incomplete_part = response[-100:]

    completion_prompt = f"""
    [INST]
    Compl√©tez UNIQUEMENT la phrase ou le paragraphe suivant en cours, sans ajouter de titre ni d'introduction.
    Contexte original: {question[:200]}...
    Texte √† compl√©ter: "{incomplete_part}"
    Consignes strictes:
    - Continuez directement le texte existant, sans recommencer la r√©ponse.
    - N'ajoutez pas de formule comme "R√©ponse du minist√®re...".- Terminez la phrase/paragraphe en cours de mani√®re coh√©rente.
    - Ajoutez une conclusion sur le th√®me de la question en 1-2 phrases maximum.
    - Utilisez un style administratif et formel, comme dans les r√©ponses minist√©rielles.
    - Respectez strictement la limite de 400 caract√®res.
    - Tout compl√©ment de r√©ponse plus long sera rejet√©.
    - Concluez en r√©affirmant l'engagement du Gouvernement.
    - La r√©ponse doit √™tre r√©dig√©e en prose continue, sans titres, sans puces, sans num√©rotation.
    - Utilisez uniquement des paragraphes r√©dig√©s, comme dans les r√©ponses minist√©rielles publi√©es au Journal Officiel.
    - Si vous avez plusieurs √©l√©ments √† pr√©senter, int√©grez-les dans des phrases compl√®tes reli√©es par des connecteurs ("par ailleurs", "en outre", "de plus").
    - Ne pas mettre de formule de politesse √† la fin.
    - Tout compl√©ment de r√©ponse qui se termine par une phrase tronqu√©e est incorrecte.
    - Toute compl√©ment de r√©ponse qui contient des listes ou des titres est incorrecte.
    [/INST]
    """

    try:
        completion_response = requests.post(
            "https://api.mistral.ai/v1/chat/completions",
            headers={"Authorization": f"Bearer {MISTRAL_API_KEY}", "Content-Type": "application/json"},
            json={
                "model": "mistral-large-latest",
                "messages": [{"role": "user", "content": completion_prompt}],
                "temperature": 0.1,
                "max_tokens": 60
            },
            timeout=30
        )
        completion_response.raise_for_status()
        completion = completion_response.json()["choices"][0]["message"]["content"]

        if response.endswith("..."):
            final_response = response[:-3] + completion
        elif response.endswith(" "):
            final_response = response + completion
        else:
            final_response = response + " " + completion

        if not final_response.endswith(('.', '!', '?')):
            final_response += "."
        return final_response

    except Exception as e:
        st.warning(f"‚ö†Ô∏è Impossible de compl√©ter la r√©ponse tronqu√©e: {str(e)}")
        return response + " (r√©ponse incompl√®te)"

# --- 7. G√©n√©ration de la r√©ponse ---
def generate_response(
    question: str,
    legislature: Optional[str] = None,
    rubrique: Optional[str] = None,
    detail_juridique: int = 3,
    longueur: str = "Moyenne (500 mots)",
    response_orientation: str = "R√©pondre de fa√ßon neutre",
    custom_instructions: str = "",
    include_legal_articles: bool = False,
    must_contain: str = "",
    max_legal_articles: int = 3,
    model_size: str = "small"   # choix du mod√®le Mistral
):
    try:
        status_placeholder = st.empty()

        # √âtape 1 : Recherche d'anciennes questions / r√©ponses parlementaires (uniquement si pas de limitation)
        parliamentary_context = "Aucun contexte parlementaire trouv√©."
        similar_documents = []
        if not (use_priority_docs and selected_docs):
            status_placeholder.markdown(
                '<div class="status-message">üèõÔ∏è Recherche dans la base des anciennes questions / r√©ponses...</div>',
                unsafe_allow_html=True
            )
            similar_documents = search_question_parlementaire(question, top_k=5)
            if similar_documents:
                parliamentary_context = "\n\n".join(
                    [
                        f"Contexte parlementaire {i+1} (source: {doc.uid}):\n"
                        f"Question: {doc.question}\nR√©ponse: {doc.reponse}"
                        for i, doc in enumerate(similar_documents)
                    ]
                )

        # √âtape 2 : Recherche des articles juridiques (si activ√©e) (uniquement si pas de limitation)

        legal_context = "Aucun texte juridique sp√©cifique n'a √©t√© identifi√©."
        legal_sources = []
        if not (use_priority_docs and selected_docs) and include_legal_articles:
            status_placeholder.markdown(
                '<div class="status-message">üìö Recherche dans les codes juridiques (Code du travail, Code de la s√©curit√© sociale, Code de la sant√© publique, Code de l\'action sociale et des familles)...</div>',
                unsafe_allow_html=True
            )
            legal_sources_result = search_articles(
                query=question,
                partie=None,
                limit=max_legal_articles,
                must_contain=must_contain if must_contain else None,
                debug=True,
                threshold=0.5
            )
            legal_sources = legal_sources_result["sources"]
            if legal_sources:
                legal_context = "\n\n".join(
                    [f"Article {art.num}: {art.titre}\n{art.article_complet}" for art in legal_sources]
                )

        # √âtape 3 : Recherche dans les documents upload√©s (si mode parlementaire) - limit√© √† 3 r√©sultats
        status_placeholder.markdown(
            '<div class="status-message">üèõÔ∏è Recherche dans la base documentaire...</div>',
            unsafe_allow_html=True
        )
        uploaded_results = search_uploaded_documents(question, qdrant_client, embedding_model, top_k=3)
        # Formatage bas√© sur la pertinence (seuil = 0.7)
        uploaded_docs_context = format_uploaded_docs_by_relevance(uploaded_results, min_score=0.7)

        # √âtape 4 : Recherche internet (si mode parlementaire)
        search_context = "Aucune recherche internet effectu√©e."
        search_results = []

        if not (use_priority_docs and selected_docs) and st.session_state.get("search_engine"):
            if st.session_state.get("search_engine") == "Tavily":
                status_placeholder.markdown(
                    '<div class="status-message">üåê Recherche internet (Tavily)...</div>',
                    unsafe_allow_html=True
                )
                results = search_tavily_government(extract_subject(question))
                search_context = results.get("answer", "")
                search_results = results.get("results", [])
                # Ajout du contenu des r√©sultats pour enrichir le contexte
                if search_results:
                    search_context += "\n\n" + "\n\n".join([item.get("content", "") for item in search_results])

            elif st.session_state.get("search_engine") == "Google":
                status_placeholder.markdown(
                    '<div class="status-message">üåê Recherche internet (Google)...</div>',
                    unsafe_allow_html=True
                )
                results = search_google_government(extract_subject(question))
                search_results = results.get("results", [])
                # Google renvoie "snippet"
                search_context = "\n\n".join([item.get("snippet", "") for item in search_results])

        # √âtape 5 : G√©n√©ration de la r√©ponse
        status_placeholder.markdown(
            '<div class="status-message">ü§ñ G√©n√©ration de la r√©ponse par Mistral...</div>',
            unsafe_allow_html=True
        )
        prompt = build_parlementary_response_prompt(
            question=question,
            parliamentary_context=parliamentary_context,
            legal_context=legal_context,
            uploaded_documents=uploaded_docs_context,
            detail_juridique=detail_juridique,
            longueur=longueur,
            response_orientation=response_orientation,
            custom_instructions=custom_instructions,
            search_context=search_context
        )
        mistral_response = call_mistral_parlementary_response(
            prompt,
            longueur,
            question,
            model_size=model_size
        )

        # ‚û°Ô∏è Effacer le message
        status_placeholder.empty()

        return {
            "question": question,
            "context": [doc.reponse for doc in similar_documents[:6] if doc.reponse],
            "context_str": parliamentary_context,
            "legal_context": legal_context,
            "response": mistral_response,
            "legal_sources": legal_sources if include_legal_articles else [],
            "similar_documents": similar_documents,
            "uploaded_documents": uploaded_results,
            "search_results": search_results,
            "metadata": {
                "status": "success",
                "model_used": f"mistral-{model_size}-latest",
                "timestamp": datetime.now(pytz.timezone('Europe/Paris')).isoformat(),
                "legislature": legislature,
                "rubrique": rubrique
            }
        }

    except Exception as e:
        return {
            "question": question,
            "response": f"Erreur lors de la g√©n√©ration de la r√©ponse : {str(e)}",
            "error": str(e),
            "legal_sources": [],
            "similar_documents": [],
            "metadata": {
                "status": "error",
                "timestamp": datetime.now(pytz.timezone('Europe/Paris')).isoformat(),
                "legislature": legislature,
                "rubrique": rubrique
            }
        }

# --- NOUVEL ENDPOINT SIMPLIFI√â POUR LISTER LES DOCUMENTS ---

# Fonction qui retourne juste les deux cat√©gories de documents - VERSION STATIQUE
def get_simple_documents_list():
    return {
        "documents": [
            {
                "type": "Questions √©crites (QE) de l'Assembl√©e nationale",
                "periode": "2017-2025",
                "description": "Questions ayant obtenu une r√©ponse minist√©rielle (avant le 1er novembre 2025)."
            },
            {
                "type": "Questions √©crites (QE) du S√©nat",
                "periode": "2017-2025",
                "description": "Collection compl√®te des questions √©crites ayant obtenu une r√©ponse minist√©rielle (avant le 1er novembre 2025)."
            }
        ]
    }

#################################################################
### -------------  2. AUTHENTIFICATION -----------------------###
#################################################################

config = {
    "credentials": {
        "usernames": {
            "Whisler": {
                "name": "Francois-Mathieu",
                "password": os.getenv("USER_WHISLER_PASSWORD")
            },
            "Delphine": {
                "name": "Caudilla Delphine",
                "password": os.getenv("USER_DELPHINE_PASSWORD")
            },
            "Isabelle": {
                "name": "Caudilla Isabelle",
                "password": os.getenv("USER_ISABELLE_PASSWORD")
            }
        }
    }
}

if 'authentication_status' not in st.session_state:
    st.session_state.authentication_status = None

def check_password():
    if st.session_state["username"] in config['credentials']['usernames']:
        stored_password = config['credentials']['usernames'][st.session_state["username"]]["password"]
        if hashlib.sha256(st.session_state["password"].encode()).hexdigest() == stored_password:
            st.session_state["authentication_status"] = True
            st.session_state["name"] = config['credentials']['usernames'][st.session_state["username"]]["name"]
            return
    st.session_state["authentication_status"] = False

# --- Connexion ou contenu principal ---

if st.session_state.authentication_status is not True:
    # Masquer la sidebar avant connexion
    st.markdown("""
        <style>
        [data-testid="stSidebar"] {display: none;}
        /* Centrer le titre */
        .auth-title {text-align: center; margin-top: 0.5rem;}
        /* Centrer le paragraphe d'intro */
        .auth-intro {text-align: center; color: #5c5c5c;}
        </style>
    """, unsafe_allow_html=True)

    # --- Page d'authentification ---
    st.markdown('<h1 class="auth-title">üîê Authentification requise</h1>', unsafe_allow_html=True)
    st.markdown('<p class="auth-intro">Veuillez entrer vos identifiants pour acc√©der au g√©n√©rateur de r√©ponses aux questions √©crites.</p>', unsafe_allow_html=True)

    # Colonnes pour r√©duire la largeur et centrer les champs
    # Ajuste les ratios pour obtenir la largeur souhait√©e (ici ~25% de la page)
    left, center, right = st.columns([3, 2, 3])
    with center:
        st.text_input("Nom d'utilisateur", key="username")
        st.text_input("Mot de passe", type="password", key="password")
        if st.button("Se connecter"):
            check_password()
            st.rerun()

    if st.session_state.authentication_status is False:
        st.error("Identifiants incorrects. Veuillez r√©essayer.")



else:
    # R√©afficher la sidebar apr√®s connexion

    st.markdown("""
        <style>
        [data-testid="stSidebar"] {display: block;}
        </style>
    """, unsafe_allow_html=True)

#################################################################
### ---- 3. AFFICHAGE DU SITE APRES CONNEXION --------------- ###
#################################################################

    # --- Initialisation de l'historique (UNIQUEMENT si non existant) ---
    if "full_historique" not in st.session_state:
        st.session_state.full_historique = {}
        save_historique()  # Sauvegarde initiale

    # --- Chargement de l'historique depuis session_state (si vide, on v√©rifie le cache) ---
    if not st.session_state.full_historique and "historique_cache" in st.session_state:
        st.session_state.full_historique = st.session_state.historique_cache

# --- 6. Configuration de la page et CSS ---
    st.markdown("""
    <style>
        /* √âlargir le conteneur principal */
        .block-container {
            max-width: 95%;
            padding-left: 2rem;
            padding-right: 2rem;
        }
        /* √âlargir les zones de saisie */
        textarea, .stTextArea textarea {
            width: 100% !important;
        }
        /* √âlargir les selectbox et sliders */
        .stSelectbox, .stSlider {
            width: 100% !important;
        }
        /* Votre CSS existant */
        .stApp { background-color: #f8f9fa; }
        .stTabs [data-baseweb="tab-list"] { gap: 0; background-color: #e9ecef; border-radius: 6px 6px 0 0; padding: 4px; }
        .stTabs [data-baseweb="tab"] { height: 36px; white-space: pre-wrap; background-color: #f8f9fa; border: none; border-radius: 4px 4px 0 0; padding: 0 12px; }
        .stTabs [aria-selected="true"] { background-color: #ffffff; font-weight: bold; color: #3d3d3d; }
        .stButton>button { background-color: #4a8bfc; color: white; border: none; border-radius: 4px; padding: 8px 16px; font-weight: 500; }
        .stButton>button:hover { background-color: #3a7bfc; }
        .stExpander { background-color: #ffffff; border: 1px solid #e9ecef; border-radius: 6px; margin-bottom: 0px; } /* ‚Üê r√©duit l‚Äôespace */
        .stTextArea textarea { font-family: 'Segoe UI', sans-serif; font-size: 16px; line-height: 1.5; }
        .stAlert { border-radius: 6px; }
        .source-text { font-family: monospace; font-size: 14px; background-color: #f8f9fa; padding: 8px; border-radius: 4px; border-left: 3px solid #4a8bfc; }
        .response-text { font-family: 'Segoe UI', sans-serif; font-size: 16px; line-height: 1.6; white-space: pre-wrap; background-color: white; padding: 16px; border-radius: 6px; border: 1px solid #e9ecef; }

        /* Nouveau : titre de l'historique */
        .history-title {
            margin-bottom: 15px;
        }

        /* Style carte avec ombre l√©g√®re pour les expanders */
        div[data-testid="stExpander"] {
            background-color: #ffffff;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            margin-bottom: 5px !important;
            box-shadow: 0 2px 6px rgba(0,0,0,0.08); /* ombre douce */
        }

    </style>
    """, unsafe_allow_html=True)

    st.title("üèõÔ∏è G√©n√©rateur de r√©ponses aux questions √©crites parlementaires")
    st.markdown("""
    Application (version Beta) de r√©ponse aux questions parlementaires,
    appuy√©e sur une base documentaire (embedding avec **camemBERT**), un moteur de recherche (**Tavily** ou **Google**) et le mod√®le **Mistral**.
    """)

#################################################################
#### -------------------- 3a. SIDEBAR  --------------------- ####
#################################################################

    with st.sidebar:

        # Bouton D√©connexion
        if st.button('D√©connexion', key="logout"):
            st.session_state.authentication_status = None
            st.rerun()

        # Message de bienvenue
        st.write(f'Bienvenue *{st.session_state["name"]}*')
    
        # --- Version du site ---
        st.markdown(
            """
            <style>
            .version-text {
                position: absolute;
                top: 5px;
                left: 0px;
                color: #555;
                font-size: 14px;
                font-style: italic;
            }
            </style>
            <div class="version-text">Version v0.1.12 (Beta)</div>
            """,
            unsafe_allow_html=True
        )   

        # S√©parateur visuel
        st.markdown("---")

        # Param√®tres de mode
        mode = st.radio(
            "Type de r√©ponse souhait√©e",
            ["R√©ponse parlementaire"], # Ajouter , "Analyse juridique" pour avoir le second mode - Permet de moduler les modes accessibles sur le site
            index=0
        )

        # Conteneur pour contr√¥ler la largeur du bouton
        button_container = st.container()
        # Initialisation des bouton √† False
        generate_parliamentary_button = False
        generate_analysis_button = False
        with button_container:
            if mode == "R√©ponse parlementaire":
                generate_parliamentary_button = st.button(
                    "G√©n√©rer la r√©ponse",
                    type="primary",
                    key="generate_parliamentary_button"
                    # Sans use_container_width pour une largeur automatique
                )
            elif mode == "Analyse juridique":
                generate_analysis_button = st.button(
                    "G√©n√©rer l'analyse",
                    type="primary",
                    key="generate_analysis_button"
                    # Sans use_container_width pour une largeur automatique
                )
        
        # Ajoutez une s√©paration visuelle suppl√©mentaire
        st.markdown("---")

        # Choix du mod√®le Mistral
        model_size = st.radio(
            "Choix du mod√®le Mistral",
            ["Small", "Medium", "Large (recommand√©)"],
            index=0
        )

        # Normaliser la valeur pour l'appel API
        model_size = model_size.lower()

        # Choix du moteur de recherche
        search_engine = st.radio(
            "Moteur de recherche internet",
            ["Google", "Tavily"],
            index=0
        )
        st.session_state["search_engine"] = search_engine

        # S√©parateur
        st.markdown("---")

        # Case √† cocher pour G√©rer la base documentaire
        if 'manage_doc_base' not in st.session_state:
            st.session_state.manage_doc_base = False

        manage_doc_base = st.checkbox(
            "G√©rer la base documentaire",
            value=st.session_state.manage_doc_base,
            key="manage_doc_base_checkbox",
            help="Active l'interface pour ajouter/supprimer des documents dans le RAG"
        )

##########################################################################
### ------ 3b. INTERFACE DE GESTION DE LA BASE DOCUMENTAIRE ---------- ###
##########################################################################

    # Initialisation du bouton search (A REPOSITIONNER)
    search_button = False
    # Affichage conditionnel de l'interface de gestion de la base documentaire
    if manage_doc_base:
        st.session_state.manage_doc_base = True  # Met √† jour l'√©tat
        st.markdown("---")
        st.markdown("#### üìö Gestion de la base documentaire")

        # 1. Liste des documents (collections)
        try:
            collections = qdrant_client.get_collections()
            collection_names = [col.name for col in collections.collections]

            protected_collections = {
                "Code de la s√©curit√© sociale",
                "Code du travail",
                "CASF",
                "QuestionParlementaire",
                "Code de la sant√© publique"
            }

            # Filtre pour ne garder que les collections "documents" (ex: "NomDuDocument_2023")
            doc_collections = [
                name for name in collection_names
                if name not in protected_collections and "_" in name  # Ex: "MonDocument_2023"
            ]

            if not doc_collections:
                st.info("Aucun document trouv√©.")
            else:
                st.markdown("**Documents disponibles :**")

                # Tri alphab√©tique sur le nom nettoy√©
                sorted_collections = sorted(
                    doc_collections,
                    key=lambda name: name.split('__')[0].replace('_', ' ').lower()
                )

                for doc_name in sorted_collections:
                    clean_name = doc_name.split('__')[0].replace('_', ' ')
                    col1, col2, col3 = st.columns([18, 1, 1])  # plus de place pour le nom

                    with col1:
                        st.markdown(f"üìÑ {clean_name}")

                    with col2:
                        if st.button("‚úèÔ∏è", key=f"rename_{doc_name}", help="Renommer le document"):
                            st.session_state.show_rename_modal = True
                            st.session_state.current_doc_to_rename = doc_name
                            st.rerun()

                    with col3:
                        if st.button("üóëÔ∏è", key=f"del_{doc_name}", help="Supprimer le document"):
                            qdrant_client.delete_collection(collection_name=doc_name)
                            st.success(f"Document '{clean_name}' supprim√©.")
                            st.rerun()

                # Fen√™tre modale de renommage
                if st.session_state.show_rename_modal:
                    doc_name = st.session_state.current_doc_to_rename
                    clean_name = doc_name.split('__')[0].replace('_', ' ')

                    with st.container():
                        st.markdown("---")
                        st.subheader(f"Renommer le document ''{clean_name}''")

                        new_name = st.text_input(
                            "Nouveau nom:",
                            value=clean_name.replace(" ", "_"),
                            key=f"new_name_{doc_name}"
                        )

                        col1, col2 = st.columns(2)

                        with col1:
                            if st.button("Valider", key=f"validate_rename_{doc_name}"):
                                if new_name.strip():
                                    try:
                                        # 1. V√©rification si le nouveau nom existe d√©j√†
                                        new_display_name = new_name.strip().replace(" ", "_")
                                        new_collection_name = f"{new_display_name}__{doc_name.split('__')[1]}"

                                        # R√©cup√®re toutes les collections existantes
                                        existing_collections = qdrant_client.get_collections()
                                        existing_names = [col.name for col in existing_collections.collections]

                                        # V√©rifie si le nouveau nom existe d√©j√†
                                        if new_collection_name in existing_names:
                                            st.error(f"‚ùå Le nom '{new_name}' existe d√©j√†. Veuillez choisir un autre nom.")
                                        else:
                                            # Initialisation de la progression
                                            progress_bar = st.progress(0)
                                            status_text = st.empty()
                                            estimated_total = 1000  # Estimation conservatrice du nombre total de points

                                            # 2. Cr√©e la nouvelle collection (0-10%)
                                            status_text.text("Cr√©ation de la nouvelle collection...")
                                            qdrant_client.create_collection(
                                                collection_name=new_collection_name,
                                                vectors_config=models.VectorParams(
                                                    size=1024,
                                                    distance=models.Distance.COSINE
                                                )
                                            )
                                            progress_bar.progress(10)

                                            # 3. R√©cup√®re les points (10-40%)
                                            status_text.text("R√©cup√©ration des donn√©es...")
                                            offset = None
                                            all_points = []

                                            while True:
                                                records, offset = qdrant_client.scroll(
                                                    collection_name=doc_name,
                                                    limit=100,
                                                    offset=offset,
                                                    with_payload=True,
                                                    with_vectors=True
                                                )

                                                for record in records:
                                                    point_dict = {
                                                        "id": str(record.id),
                                                        "vector": record.vector,
                                                        "payload": record.payload
                                                    }
                                                    all_points.append(models.PointStruct(**point_dict))

                                                if offset is None:
                                                    break

                                                # Calcul s√©curis√© de la progression (max 40%)
                                                current_progress = min(40, 10 + int(30 * len(all_points) / max(1, estimated_total)))
                                                progress_bar.progress(current_progress)

                                            # 4. Copie les points (40-90%)
                                            status_text.text(f"Copie des {len(all_points)} chunks...")
                                            batch_size = 50

                                            for i in range(0, len(all_points), batch_size):
                                                batch = all_points[i:i + batch_size]
                                                qdrant_client.upsert(
                                                    collection_name=new_collection_name,
                                                    points=batch,
                                                    wait=True
                                                )

                                                # Calcul S√âCURIS√â de la progression (max 90%)
                                                batch_progress = min(90, 40 + int(50 * (i + len(batch)) / max(1, len(all_points))))
                                                progress_bar.progress(batch_progress)

                                            # 5. Supprime l'ancienne collection (100%)
                                            status_text.text("Finalisation...")
                                            qdrant_client.delete_collection(collection_name=doc_name)
                                            progress_bar.progress(100)

                                            st.success(f"‚úÖ Document renomm√© en '{new_name}' !")
                                            st.session_state.show_rename_modal = False
                                            st.rerun()

                                    except Exception as e:
                                        st.error(f"Erreur: {e}")
                                else:
                                    st.warning("Veuillez entrer un nom valide.")


                        with col2:
                            if st.button("Annuler", key=f"cancel_rename_{doc_name}"):
                                st.session_state.show_rename_modal = False
                                st.rerun()

        except Exception as e:
            st.error(f"Erreur: {e}")

        # 2. Section d'upload de documents
        st.markdown("---")
        st.markdown("**Ajouter un document**")

        uploaded_file = st.file_uploader(
            "S√©lectionnez un PDF ou Word",
            type=["pdf", "docx"],
            key="doc_uploader"
        )

        if uploaded_file:
            # Champ pour le nom personnalis√© (sera aussi le nom de la collection)
            default_name = os.path.splitext(uploaded_file.name)[0]
            custom_name = st.text_input(
                "Nom du document (sera aussi le nom de la collection):",
                value=default_name,
                key="doc_name_input"
            )

            if st.button("Ajouter le document", key="add_document"):
                if not custom_name.strip():
                    st.warning("Veuillez entrer un nom valide.")
                else:
                    # G√©n√©ration du nom de la collection (avec timestamp cach√© pour l'unicit√©)
                    display_name = custom_name.strip().replace(" ", "_")  # Nom affich√© (sans timestamp)
                    collection_name = f"{display_name}__{int(datetime.now().timestamp())}"  # Nom interne (avec timestamp)

                    # Initialisation de la barre de progression
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    def update_progress(current, total, message):
                        """Met √† jour la barre de progression et le statut."""
                        percent = int((current / total) * 100) if total > 0 else 0
                        progress_bar.progress(percent)
                        status_text.text(f"{message} ({current}/{total})")

                    try:
                        # Cr√©ation de la collection
                        status_text.text("Cr√©ation de la collection dans Qdrant...")
                        qdrant_client.create_collection(
                            collection_name=collection_name,
                            vectors_config=models.VectorParams(
                                size=1024,
                                distance=models.Distance.COSINE
                            )
                        )

                        # Sauvegarde du fichier temporaire
                        status_text.text("Sauvegarde du fichier temporaire...")
                        with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
                            tmp_file.write(uploaded_file.getvalue())
                            tmp_path = tmp_file.name

                        # Appel de la fonction avec callback
                        status_text.text("Traitement et indexation en cours...")
                        success = process_and_index_document(
                            file_path=tmp_path,
                            file_type=uploaded_file.name.split('.')[-1],
                            collection_name=collection_name,
                            qdrant_client=qdrant_client,
                            embedding_model=embedding_model,
                            progress_callback=update_progress  # ‚Üê Callback ajout√©
                        )

                        if success:
                            status_text.text("Document ajout√© avec succ√®s !")
                            progress_bar.progress(100)
                            st.success(f"‚úÖ Document ajout√© sous le nom '{custom_name}' !")

                            if os.path.exists(tmp_path):
                                os.unlink(tmp_path)

                            st.session_state.manage_doc_base = False
                            st.rerun()
                        else:
                            status_text.text("√âchec de l'ajout du document")
                            st.error("‚ùå √âchec de l'ajout.")

                    except Exception as e:
                        status_text.text(f"Erreur: {str(e)}")
                        st.error(f"Erreur: {e}")
                    finally:
                        time.sleep(2)  # Laisse le temps de voir le r√©sultat
                        progress_bar.empty()
                        status_text.empty()

#########################################################################################
#### ---------- 3c. INTERFACE DE REPONSE AUX QUESTIONS PARLEMENTAIRES -------------- ####
#########################################################################################

    else:
        st.markdown("#### Question parlementaire")
        question = st.text_area(
            "Question parlementaire",   # libell√© non vide
            height=150,
            placeholder="Copier ici le texte de la question parlementaire",
            key="question_input",
            label_visibility="collapsed"
        )

        # Initialisation des variables des boutons (pour √©viter NameError)
        search_button = False

        # --- Boutons conditionnels selon le mode ---
        if mode == "R√©ponse parlementaire":
            # --- Param√®tres de r√©ponse ---
            st.markdown("#### Param√®tres de r√©ponse")
            col1, col2, col3 = st.columns(3)
            with col1:
                response_orientation_options = [
                    "R√©pondre de fa√ßon neutre",
                    "R√©pondre n√©gativement aux propositions du parlementaire",
                    "R√©pondre positivement aux propositions du parlementaire",
                    "R√©pondre de mani√®re technique et d√©taill√©e"
                ]
                selected_orientation = st.selectbox(
                    "Orientation de la r√©ponse",
                    response_orientation_options,
                    index=0
                )
            with col2:
                longueur = st.selectbox(
                    "Longueur de la r√©ponse",
                    ["Courte (300 mots)", "Moyenne (500 mots)", "Longue (1000 mots)"],
                    index=1
                )
            with col3:
                include_legal_articles = st.selectbox(
                    "Inclure une recherche dans les codes juridiques",
                    ["Non", "Oui"],
                    index=0,
                    key="include_legal_articles_select"
                ) == "Oui"

            MAX_LEN = 300

            # Ligne avec deux colonnes : champ texte + case √† cocher
            colA, colB = st.columns([2, 1])

            with colA:
                MAX_LEN = 300
                custom_instructions = st.text_area(
                    "Optionnel : instructions suppl√©mentaires pour la r√©ponse (max. 300 caract√®res)",
                    placeholder="Ex: Insister sur l'aspect budg√©taire, mentionner le projet de loi X...",
                    height=100,
                    key="custom_instructions"
                )
                if custom_instructions:
                    remaining = MAX_LEN - len(custom_instructions)
                    if remaining < 0:
                        st.warning(f"‚ö†Ô∏è Vous avez d√©pass√© la limite de {MAX_LEN} caract√®res ({len(custom_instructions)} actuellement).")
                        custom_instructions = custom_instructions[:MAX_LEN]

            with colB:
                detail_juridique = st.slider(
                    "Niveau de d√©tail juridique (1 = bas, 5 = √©lev√©)",
                    min_value=1,
                    max_value=5,
                    value=3
                )

                if include_legal_articles:
                    must_contain = st.text_input(
                        "Optionnel : les articles s√©lectionn√©s doivent contenir (mot ou expression exacte)",
                        key="must_contain_input",
                        placeholder="Ex: allocation, article 123, d√©cret 2020-..."
                    )
                else:
                    must_contain = ""

            st.markdown("**Limiter les documents sources** (attention : la r√©ponse n'int√®gre ni plus les anciennes QE, ni les textes juridiques et ni la recherche internet)")
            use_priority_docs = st.checkbox(
                "Rechercher uniquement dans les documents suivants :",
                value=False,
                key="use_priority_docs"
            )

            if use_priority_docs:
                # R√©cup√®re les collections "documents"
                collections = qdrant_client.get_collections()
                doc_collections = [
                    col.name for col in collections.collections
                    if col.name not in {"Code_de_la_s√©curit√©_sociale", "Code_du_travail", "CASF", "QuestionParlementaire", "Code_de_la_sant√©_publique"}
                    and "_" in col.name
                ]

                # Affiche les noms propres (sans timestamp)
                doc_names = [col.split('__')[0].replace('_', ' ') for col in doc_collections]
                selected_docs = st.multiselect(
                    "S√©lectionnez les documents",
                    options=doc_names,
                    key="priority_docs",
                    placeholder="Choisir..."
                )

        elif mode == "Analyse juridique":
            # --- Param√®tres de recherche juridique ---
            st.markdown("### Param√®tres de recherche juridique")
            col1, col2, col3 = st.columns(3)
            with col1:
                must_contain = st.text_input("üîé Doit contenir (mot ou expression exacte)", key="must_contain_input")
            with col2:
                threshold = st.selectbox(
                    "üìä Seuil de s√©lection",
                    [0.4, 0.5, 0.6, 0.65, 0.70, 0.75, 0.80, 0.85],
                    index=2,
                    key="threshold_select"
                )
            with col3:
                max_articles = st.number_input(
                    "üìå Nombre maximum d'articles",
                    min_value=1,
                    max_value=30,
                    value=5,
                    key="max_articles_input"
                )

            # --- Affichage du bouton d'analyse juridique ---
            search_button = st.button("Rechercher les articles", type="secondary", key="search_button")

###################################################################
#### --------------- 4. GENERATION DE LA REPONSE ------------- ####
###################################################################

    if generate_parliamentary_button or search_button or generate_analysis_button:
        if not question.strip():
            st.warning("Veuillez entrer une question.")
        else:
            try:
                debug_logs = ""
                response_data = {}
                stats = {}

                if mode == "R√©ponse parlementaire":
                    # Logique inchang√©e pour le mode "R√©ponse parlementaire"
                    response_data = generate_response(
                        question=question,
                        detail_juridique=detail_juridique,
                        longueur=longueur,
                        response_orientation=selected_orientation,
                        custom_instructions=custom_instructions,
                        include_legal_articles=include_legal_articles,
                        must_contain=must_contain if include_legal_articles else "",
                        max_legal_articles=detail_juridique # le nombre d'articles est √©gal au niveau de d√©tail juridique
                    )

                elif mode == "Analyse juridique":
                    response_data = generate_legal_analysis(
                        question=question,
                        must_contain=must_contain,
                        max_articles=max_articles,
                        threshold=threshold,
                        model_size=model_size,
                        search_button=search_button,  # Bouton "Rechercher les articles"
                        generate_analysis_button=generate_analysis_button  # Bouton "G√©n√©rer l'analyse"
                    )

                # D√©termination des onglets √† afficher
                tabs = []
                if mode == "R√©ponse parlementaire":
                    tabs = ["üìú R√©ponse"]
                    if include_legal_articles:
                        tabs.append("‚öñÔ∏è Articles juridiques")
                    tabs.extend(["üèõÔ∏è Anciennes QE", "üì∞ Recherches actualit√©s", "üìÑ Base documentaire"])
                elif mode == "Analyse juridique":
                    tabs = ["‚öñÔ∏è Articles juridiques"]
                    if generate_analysis_button and response_data.get("response"):
                        tabs.insert(0, "üìú Analyse")  # Ajoute "Analyse" en premier si g√©n√©r√©e

                # Cr√©ation dynamique des onglets
                if tabs:
                    st_tabs = st.tabs(tabs)

                    # Affichage du contenu en fonction des onglets
                    for i, tab in enumerate(st_tabs):
                        with tab:
                            if mode == "R√©ponse parlementaire":
                                if "üìú R√©ponse" in tabs[i]:
                                    st.markdown("#### R√©ponse g√©n√©r√©e")
                                    st.markdown(response_data["response"])
                                    if response_data.get("debug_logs"):
                                        with st.expander("üêõ Voir les logs de recherche"):
                                            st.text_area("Logs", response_data["debug_logs"], height=200)
                                    # Bouton d'export
                                    if response_data.get("response"):
                                        export_content = build_export_content(
                                            response_data,
                                            mode="parlementaire",  # ‚Üê Mode cod√© en dur (valide car dans le bloc "R√©ponse parlementaire")
                                            include_legal_articles=include_legal_articles  # ‚Üê Utilise la variable existante
                                        )
                                        st.download_button(
                                            label="üì• Exporter en TXT",
                                            data=export_content.encode("utf-8"),
                                            file_name="export_reponse_parlementaire.txt",  # ‚Üê Nom de fichier plus clair
                                            mime="text/plain",
                                            key=f"export_reponse_{i}"  # ‚Üê Cl√© unique bas√©e sur l'index
                                        )
                                    st.markdown('<div style="height: 300px;"></div>', unsafe_allow_html=True)

                                elif "üèõÔ∏è Anciennes QE" in tabs[i]:
                                    st.markdown("#### 5 Questions parlementaires les plus similaires de la plus r√©cente √† la plus ancienne")
                                    if not response_data.get("similar_documents"):
                                        st.info("Aucune question parlementaire similaire trouv√©e.")
                                    else:
                                        similar_documents = response_data["similar_documents"]

                                        # Tri par date d√©croissante
                                        similar_documents = sorted(
                                            similar_documents,
                                            key=lambda d: safe_parse_date(d.date_reponse),
                                            reverse=True
                                        )

                                        # Affichage avec score
                                        for idx, doc in enumerate(similar_documents):
                                            chambre = doc.chambre or ("Assembl√©e nationale" if str(doc.uid).startswith("QAN") else "S√©nat")
                                            date_reponse = doc.date_reponse or "Inconnue"
                                            question_text = doc.question or "Question non disponible"
                                            reponse_text = doc.reponse or "R√©ponse non disponible"
                                            score = f"{doc.score:.2f}" if doc.score is not None else "N/A"

                                            with st.expander(f"{idx+1}. QE {doc.uid} ({chambre}) - Score de proximit√© : {score}"):
                                                st.markdown(f"**Date de r√©ponse:** {date_reponse}")
                                                st.markdown(f"**Chambre:** {chambre}")
                                                st.markdown(f"**Question:** {question_text}")
                                                st.markdown(f"**R√©ponse:** {reponse_text}")

                                    st.markdown('<div style="height: 300px;"></div>', unsafe_allow_html=True)

                                elif "‚öñÔ∏è Articles juridiques" in tabs[i]:
                                    st.markdown("#### Articles juridiques pertinents")

                                    legal_sources = response_data.get("legal_sources", [])

                                    if not legal_sources:
                                        st.info("Aucun texte juridique cit√©.")
                                    else:
                                        for idx, art in enumerate(legal_sources):
                                            score = f"{art.score:.2f}" if art.score is not None else "N/A"
                                            with st.expander(f"{idx+1}. Article {art.num} ({art.collection}) - Score : {score}"):
                                                st.markdown(f"**Titre:** {art.titre}")
                                                st.markdown(f"**Contexte hi√©rarchique:** {art.contexte_hierarchique}")
                                                st.markdown(f"**Texte complet:**\n\n{art.article_complet}")

                                elif "üì∞ Recherches actualit√©s" in tabs[i]:
                                    st.markdown("#### Derni√®res annonces et actualit√©s gouvernementales")
                                    search_results = response_data.get("search_results", [])
                                    if not search_results:
                                        st.info("Aucune actualit√© trouv√©e via le moteur de recherche.")
                                    else:
                                        for idx, item in enumerate(search_results):
                                            titre = item.get("title", "Sans titre")
                                            url = item.get("url", "")
                                            # Utiliser "content" pour Tavily, "snippet" pour Google
                                            extrait = item.get("content") or item.get("snippet") or ""
                                            with st.expander(f"{idx+1}. {titre}"):
                                                if url:
                                                    st.markdown(f"[Lien vers la source]({url})")
                                                if extrait:
                                                    st.markdown(extrait)

                                elif "üìÑ Base documentaire" in tabs[i]:
                                    st.markdown("#### R√©sultats pertinents dans les documents upload√©s")

                                    uploaded_results = response_data.get("uploaded_documents", [])

                                    # Filtrer par score
                                    min_score = 0.7
                                    filtered_results = [res for res in uploaded_results if res.get("score", 0) >= min_score]

                                    if not filtered_results:
                                        st.info("Aucun extrait pertinent trouv√© dans les documents upload√©s.")
                                    else:
                                        # Regrouper par document
                                        grouped = {}
                                        for res in filtered_results:
                                            doc_name = res["collection"].split('__')[0].replace('_', ' ')
                                            grouped.setdefault(doc_name, []).append(res)

                                        for doc_name, results in grouped.items():
                                            with st.expander(f"üìÑ {doc_name} ({len(results)} extraits)"):
                                                for idx, res in enumerate(results, start=1):
                                                    score = f"{res['score']:.2f}" if res.get("score") is not None else "N/A"
                                                    text_preview = res["text"]
                                                    title = res.get("title") or "N/A"

                                                    st.markdown(f"**Extrait {idx} (score: {score})**")
                                                    st.markdown(text_preview)
                                                    st.markdown(f"**Section :** {title}")
                                                    st.markdown("---")

                                                # Actions sur la collection
                                                col1, col2 = st.columns([1, 1])
                                                target_collection = results[0]["collection"]
                                                with col1:
                                                    if st.button("‚úèÔ∏è Renommer", key=f"rename_{target_collection}"):
                                                        st.session_state.show_rename_modal = True
                                                        st.session_state.current_doc_to_rename = target_collection
                                                        st.rerun()
                                                with col2:
                                                    if st.button("üóëÔ∏è Supprimer", key=f"del_{target_collection}"):
                                                        qdrant_client.delete_collection(collection_name=target_collection)
                                                        st.success(f"Document '{doc_name}' supprim√©.")
                                                        st.rerun()

                            elif mode == "Analyse juridique":
                                if "üìú Analyse" in tabs[i]:
                                    st.markdown("#### Analyse juridique g√©n√©r√©e")
                                    st.markdown(response_data["response"])

                                    # Affichage des logs (si disponibles)
                                    if response_data.get("debug_logs"):
                                        with st.expander("üêõ Voir les logs de recherche"):
                                            st.text_area("Logs", response_data["debug_logs"], height=200)

                                    # Bouton d'export
                                    if response_data.get("response"):
                                        export_content = build_export_content(
                                            response_data,
                                            mode="analyse",  # Mode pour l'export
                                            include_legal_articles=False
                                        )
                                        st.download_button(
                                            label="üì• Exporter en TXT",
                                            data=export_content.encode("utf-8"),
                                            file_name=f"analyse_juridique_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",  # Nom de fichier unique
                                            mime="text/plain",
                                            key=f"export_analyse_{i}"
                                        )
                                    st.markdown('<div style="height: 300px;"></div>', unsafe_allow_html=True)

                                elif "‚öñÔ∏è Articles juridiques" in tabs[i]:
                                    st.markdown("#### Articles juridiques pertinents")

                                    # V√©rification de la pr√©sence de sources
                                    if not response_data.get("sources"):
                                        st.info("Aucun article juridique trouv√©.")
                                    else:
                                        # Construction de l'arbre l√©gislatif (comme dans ton code original)
                                        tree = {}
                                        for source in response_data["sources"]:
                                            art = source["article"]  # Objet RetrievedLegalDocument
                                            add_to_tree(tree, art, source)  # Ajoute l'article √† l'arbre

                                        # Affichage de l'arbre avec render_tree
                                        render_tree(st, tree)


            except Exception as e:
                st.error(f"Erreur inattendue: {str(e)}")
                st.exception(e)

###################################################################
#### -------- 5. GESTION ET AFFICHAGE DE L'HISTORIQUE -------- ####
###################################################################

    # Initialisation du mode
    mode_value = mode.lower().replace(" ", "_")  # "r√©ponse_parlementaire" ou "analyse_juridique"
    # Ajout d'une entr√©e √† l'historique apr√®s g√©n√©ration d'une r√©ponse
    if generate_parliamentary_button or generate_analysis_button:
        if not question.strip():
            st.warning("Veuillez entrer une question.")
        else:
            try:
                # G√©n√©ration d'une cl√© unique pour la question
                q_hash = hashlib.md5(question.encode()).hexdigest()
                # Pr√©paration des m√©tadonn√©es communes
                metadata = {
                    "mode": mode_value,
                    "timestamp": datetime.now(pytz.timezone('Europe/Paris')).isoformat(),
                    "model_used": f"mistral-{model_size}-latest",
                    "include_legal_articles": include_legal_articles if mode_value == "parlementaire" else False,
                    "legislature": None,
                    "rubrique": None
                }

                # Filtrer les documents upload√©s par score (seuil = 0.7)
                min_score = 0.7
                uploaded_docs_filtered = [
                    res for res in response_data.get("uploaded_documents", [])
                    if res.get("score", 0) >= min_score
                ]

                # Ajout √† l'historique
                st.session_state.full_historique[q_hash] = {
                    "question": question,
                    "response": response_data.get("response", "Pas de r√©ponse g√©n√©r√©e"),
                    "similar_documents": response_data.get("similar_documents", []),
                    "legal_sources": response_data.get("legal_sources", []),
                    "sources": response_data.get("sources", []),  # Pour le mode "analyse"
                    "search_results": response_data.get("search_results", []),
                    "uploaded_documents": uploaded_docs_filtered,
                    "metadata": metadata
                }
                save_historique()  # Sauvegarde imm√©diate
            except Exception as e:
                st.error(f"Erreur lors de l'ajout √† l'historique: {str(e)}")

    # --- Affichage de l'historique complet ---
    st.markdown("""
    <style>
        /* Centrage du bloc historique */
        .history-container {
            max-width: 1000px;
            margin-left: auto;
            margin-right: 0;
            padding-left: 1rem;
        }
        /* Style des expanders */
        .history-expander {
            margin-bottom: 0.5rem !important;
            border: 1px solid #e9ecef;
            border-radius: 8px;
        }
        /* Espacement des √©l√©ments */
        .history-entry {
            margin-bottom: 1rem;
        }
    </style>
    """, unsafe_allow_html=True)

    # Conteneur pour centrer √† gauche
    with st.container():
        st.markdown('<div class="history-container">', unsafe_allow_html=True)

        if hasattr(st.session_state, 'full_historique') and st.session_state.full_historique:
            nb_entries = len(st.session_state.full_historique)
            st.markdown(
                f"""
                <div style="display:flex;align-items:center;gap:10px;margin-bottom:1rem;">
                    <span style="font-size:18px;font-weight:bold;">üóÇÔ∏è Historique des questions ({nb_entries})</span>
                </div>
                """,
                unsafe_allow_html=True
            )

            # Tri du plus r√©cent au plus ancien
            sorted_historique = sorted(
                st.session_state.full_historique.items(),
                key=lambda x: x[1]["metadata"].get("timestamp", ""),
                reverse=True
            )

            for idx, (q_hash, entry) in enumerate(sorted_historique):
                with st.expander(f"{idx+1}. {truncate_text(entry['question'], max_tokens=50)}", expanded=False):
                    # M√©tadonn√©es
                    metadata = entry.get("metadata", {})
                    st.caption(
                        f"üïí {metadata.get('timestamp', '')[:16].replace('T', ' ')} "
                        f"| Mode: {metadata.get('mode', 'inconnu')} "
                        f"| Mod√®le: {metadata.get('model_used', 'inconnu')}"
                    )

                    # Question
                    st.markdown(f"**üìù Question:**\n{entry.get('question', 'Non disponible')}")

                    # R√©ponse (sans duplication)
                    st.markdown(f"**üí¨ R√©ponse:**")
                    st.markdown(entry.get('response', 'Non disponible'))

                    # --- Sources juridiques (si disponibles) ---
                    if entry.get("legal_sources") or entry.get("sources"):
                        with st.expander("‚öñÔ∏è Articles juridiques"):
                            if metadata.get("mode") == "analyse_juridique":  # Note : "analyse_juridique" (avec underscore)
                                # Mode "Analyse juridique" : utilise "sources" et affiche l'arbre l√©gislatif
                                if not entry.get("sources"):
                                    st.info("Aucun article juridique enregistr√©.")
                                else:
                                    # Construction de l'arbre l√©gislatif
                                    tree = {}
                                    for source in entry["sources"]:
                                        art = source["article"]
                                        add_to_tree(tree, art, source)  # Utilise la fonction existante

                                    # Affichage de l'arbre
                                    render_tree(st, tree)  # Utilise la fonction existante

                            else:  # Mode "R√©ponse parlementaire" : utilise "legal_sources"
                                for art in entry.get("legal_sources", []):
                                    with st.expander(f"Article {getattr(art, 'num', 'N/A')} ({getattr(art, 'collection', 'N/A')})"):
                                        st.markdown(f"**Titre:** {getattr(art, 'titre', 'Non disponible')}")
                                        st.markdown(f"**Texte:**\n{getattr(art, 'article_complet', 'Non disponible')}")

                    # --- R√©sultats de recherche internet (si disponibles) ---
                    if entry.get("search_results"):
                        with st.expander("üåê R√©sultats de recherche internet"):
                            for item_idx, item in enumerate(entry["search_results"]):
                                with st.expander(f"{item_idx+1}. {item.get('title', 'Sans titre')}"):
                                    if item.get("url"):
                                        st.markdown(f"[Lien]({item.get('url')})")
                                    st.markdown(item.get("content") or item.get("snippet", "Aucun extrait disponible"))

                    # --- Anciennes QE similaires (si disponibles) ---
                    if entry.get("similar_documents"):
                        with st.expander("üèõÔ∏è Questions parlementaires similaires"):
                            for doc_idx, doc in enumerate(entry["similar_documents"]):
                                with st.expander(f"QE {doc_idx+1} - Score: {getattr(doc, 'score', 'N/A'):.2f}"):
                                    st.markdown(f"**Question:** {getattr(doc, 'question', 'Non disponible')}")
                                    st.markdown(f"**R√©ponse:** {getattr(doc, 'reponse', 'Non disponible')}")

                    # --- R√©sultats vectoriels sur documents upload√©s ---
                    if entry.get("uploaded_documents"):
                        with st.expander("üìÑ Documents upload√©s pertinents"):
                            # Regrouper par document
                            grouped = {}
                            for res in entry["uploaded_documents"]:
                                doc_name = res["collection"].split('__')[0].replace('_', ' ')
                                grouped.setdefault(doc_name, []).append(res)

                            for doc_name, results in grouped.items():
                                with st.expander(f"üìÑ {doc_name} ({len(results)} extraits)"):
                                    for idx_res, res in enumerate(results, start=1):
                                        score = f"{res['score']:.2f}" if res.get("score") is not None else "N/A"
                                        text_full = res["text"]  # ‚úÖ affichage complet
                                        title = res.get("title") or "N/A"

                                        st.markdown(f"**Extrait {idx_res} (score: {score})**")
                                        st.markdown(text_full)
                                        st.markdown(f"**Section :** {title}")
                                        st.markdown("---")

                    # Boutons d'action
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        export_content = build_export_content(
                            entry,
                            mode=metadata.get("mode", "parlementaire"),
                            include_legal_articles=metadata.get("include_legal_articles", False)
                        )
                        st.download_button(
                            label="‚¨áÔ∏è Exporter en TXT",
                            data=export_content.encode("utf-8"),
                            file_name=f"export_{idx+1}_{metadata.get('mode', 'parlementaire')}.txt",
                            mime="text/plain",
                            key=f"export_hist_{q_hash}"
                        )
                    with col2:
                        if st.button("üóëÔ∏è Supprimer", key=f"del_hist_{q_hash}"):
                            del st.session_state.full_historique[q_hash]
                            save_historique()
                            st.rerun()

        else:
            st.info("Aucune question enregistr√©e dans l'historique pour le moment.")

        st.markdown('</div>', unsafe_allow_html=True)
